{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e218368-0e0a-4cdf-accb-698b731c39de",
   "metadata": {},
   "source": [
    "# Intro aux index\n",
    "\n",
    "## SQL DB vs Index\n",
    "Les index sont des cousins des bases de données (DB - databse) dans le sens où ils stockent de la données et permettent d'y accéder via des requêtes. Commençons par voir les index comme des DB munis d'une seule table qui contient des **documents** qu'un utilisateur voudra requêter. Les index ne sont pas capables de jointure et les opérations classiques du SQL y sont difficiles (`GROUP BY`) voire simplement impossibles (`JOIN`, `ROW NUMBER`). Appelons *corpus* l'ensemble de documents indéxés.\n",
    "\n",
    "NB: dans une moindre mesure, les *index* sont régulièrement utilisés dans les coulisses des DB SQL sur les clefs fréquemment manipulés. On y reviendra.\n",
    "\n",
    "### Alors à quoi sert un index ?\n",
    "\n",
    "Un **index** est un puissant outil *pour retrouver des documents à partir de **query** sur leurs attributs, une partie de leurs attributs, ou d'une information partielle sur leurs attributs*. De plus, ces outils sont souvent équipés d'un système de **scores d'adéquation** qui *ordonnent* les documents par ordre de pertinence face à la query.\n",
    "\n",
    "Il existe une infinité de façon de définir un score d'adéquation. En effet, il ne s'agit \"que\" d'un calcul opéré sur le coupe `(query, document)` et qui propose une mesure de l'adéquation query/document. Nous parlerons simplement de *score* par la suite\n",
    "\n",
    "# Index lexical\n",
    "\n",
    "## Structure de donné de l'index lexical inversé\n",
    "\n",
    "Un index est capable de retrouver extrêmement vite des attributs d'un documents à partir d'une requête. Les index sont équipés de structures de données complexes permettant d'insérer des documents et d'y effectuer des recherches en complexité $O(\\log n)$ (où $n$ est le nombre de documents). Contrairement à une `hashMap`, il ne s'agit pas de simplement `get` un document via son identifiant (auquel cas il s'agit d'une compléxité de $O(1)$) mais de trouver *tous les documents qui correspondent à une recherche*. \n",
    "\n",
    "Exemple : trouver tous les documents qui contiennent le mot `pils`. \n",
    "\n",
    "Un index maintient une [\"posting list\" ou \"index inversé\"](https://www.wikiwand.com/en/articles/Inverted_index) en mémoire : à la façon d'un glossaire dans un livre, l'index maintient en mémoire un vocabulaire (les mots contenus dans tout le corpus) ainsi que, pour chaque mot, **la liste de tous les documents qui l'évoquent ainsi que les positions du mot dans les documents**. Trouver les documents qui contiennent une série de mot devient rapide : $O(\\log n)$.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec2123-e42e-4a9c-9f0a-877d7784886e",
   "metadata": {},
   "source": [
    "Soit le (mini) corpus suivant\n",
    "- \"portez ce vieux whiskey au juge blond qui fume\"\n",
    "- \"On fume ce type de malts pour obtenir ce whiskey tourbé\"\n",
    "\n",
    "Calculons la `posting_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c297ec7-5097-417c-a2f5-e7acf38f6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"portez ce vieux whiskey au juge blond qui fume\",\n",
    "    \"On fume ce malt pour obtenir ce whiskey tourbé\",\n",
    "    \"La fermentation haute donne des bières plus fruitées.\", \n",
    "    \"Ce houblon ajoute une amertume distincte à la bière.\", \n",
    "    \"Le malt apporte la rondeur à la bière mais un malt torréfié apporte des arômes de café à la bière.\", \n",
    "    \"La bière de fermentation basse est plus légère et rafraîchissante.\", \n",
    "    \"La température de fermentation influence le goût final de la bière.\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "512bf6fe-81cf-4437-90a7-448845d80f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "vocab = sorted(set([word for doc in corpus for word in doc.lower().split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b21b5fc7-7c02-4109-83a5-b526ae89d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute posting list in a naïve whay\n",
    "posting_list = {\n",
    "    word: {\n",
    "        f\"doc-{doc_id}\": [i for i, w in enumerate(doc_str.lower().split()) if w == word]\n",
    "        for doc_id, doc_str in enumerate(corpus)\n",
    "        if \" \" + word + \" \" in doc_str.lower()\n",
    "    }\n",
    "    for word in vocab\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9785c435-c194-4ed4-ba3e-5cd6d243500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ajoute': {'doc-3': [2]},\n",
       " 'amertume': {'doc-3': [4]},\n",
       " 'apporte': {'doc-4': [2, 12]},\n",
       " 'arômes': {'doc-4': [14]},\n",
       " 'au': {'doc-0': [4]},\n",
       " 'basse': {'doc-5': [4]},\n",
       " 'bière': {'doc-4': [7], 'doc-5': [1]},\n",
       " 'bière.': {},\n",
       " 'bières': {'doc-2': [5]},\n",
       " 'blond': {'doc-0': [6]},\n",
       " 'café': {'doc-4': [16]},\n",
       " 'ce': {'doc-0': [1], 'doc-1': [2, 6]},\n",
       " 'de': {'doc-4': [15], 'doc-5': [2], 'doc-6': [2, 8]},\n",
       " 'des': {'doc-2': [4], 'doc-4': [13]},\n",
       " 'distincte': {'doc-3': [5]},\n",
       " 'donne': {'doc-2': [3]},\n",
       " 'est': {'doc-5': [5]},\n",
       " 'et': {'doc-5': [8]},\n",
       " 'fermentation': {'doc-2': [1], 'doc-5': [3], 'doc-6': [3]},\n",
       " 'final': {'doc-6': [7]},\n",
       " 'fruitées.': {},\n",
       " 'fume': {'doc-1': [1]},\n",
       " 'goût': {'doc-6': [6]},\n",
       " 'haute': {'doc-2': [2]},\n",
       " 'houblon': {'doc-3': [1]},\n",
       " 'influence': {'doc-6': [4]},\n",
       " 'juge': {'doc-0': [5]},\n",
       " 'la': {'doc-3': [7], 'doc-4': [3, 6, 18], 'doc-6': [0, 9]},\n",
       " 'le': {'doc-6': [5]},\n",
       " 'légère': {'doc-5': [7]},\n",
       " 'mais': {'doc-4': [8]},\n",
       " 'malt': {'doc-1': [3], 'doc-4': [1, 10]},\n",
       " 'obtenir': {'doc-1': [5]},\n",
       " 'on': {},\n",
       " 'plus': {'doc-2': [6], 'doc-5': [6]},\n",
       " 'portez': {},\n",
       " 'pour': {'doc-1': [4]},\n",
       " 'qui': {'doc-0': [7]},\n",
       " 'rafraîchissante.': {},\n",
       " 'rondeur': {'doc-4': [4]},\n",
       " 'température': {'doc-6': [1]},\n",
       " 'torréfié': {'doc-4': [11]},\n",
       " 'tourbé': {},\n",
       " 'un': {'doc-4': [9]},\n",
       " 'une': {'doc-3': [3]},\n",
       " 'vieux': {'doc-0': [2]},\n",
       " 'whiskey': {'doc-0': [3], 'doc-1': [7]},\n",
       " 'à': {'doc-3': [6], 'doc-4': [5, 17]}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posting_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99365001-d612-4979-a232-66655884bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc-1': [3], 'doc-4': [1, 10]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posting_list[\"malt\"] # appel à une hash-map => complexité en O(1) pour trouver les passages de tous les docs qui parlent d'un mot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ffb5cb3-f799-4db1-952d-c605ba6da92d",
   "metadata": {},
   "source": [
    "## BM25 : score de priorité pour un index lexical\n",
    "Le score de référence dans le domaine de la recherche lexicale est le [BM25](https://www.wikiwand.com/fr/articles/Okapi_BM25) (pas nécessaire de comprendre les formules). En première approximation, supposons que ce score attribué à chaque document calcule, pour chaque mot de la query, la fréquence d'apparition du mot dans le document pondéré par des notions de rareté du mot dans le corpus (une `posting_list` permet d'obtenir cette information très facilement).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a06b010e-914b-4749-80f3-03854553c41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results(documents=array([['Le malt apporte la rondeur à la bière mais un malt torréfié apporte des arômes de café à la bière.',\n",
       "        'On fume ce malt pour obtenir ce whiskey tourbé',\n",
       "        'La température de fermentation influence le goût final de la bière.']],\n",
       "      dtype='<U98'), scores=array([[0.5355514, 0.5169559, 0.       ]], dtype=float32))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bm25s import BM25, tokenize\n",
    "\n",
    "# Tokenize the corpus and index it\n",
    "corpus_tokens = tokenize(corpus)\n",
    "retriever = BM25(corpus=corpus)\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "retriever.retrieve(tokenize(\"malt\"), k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f648b-00c8-44c9-a5bb-e3fecef8ddd6",
   "metadata": {},
   "source": [
    "## Index Vespa\n",
    "[Vespa](https://vespa.ai/) est un index moderne, puissant, hautement distribué, concurrent du très connu [ElasticSearch](https://www.elastic.co/fr/). Ces 2 index permettent d'être utilisés en mode lexical pour de la recherche d'information dans un corpus.\n",
    "\n",
    "Nous utiliserons Vespa pendant ce TP : ne pas hésiter à [aller voir la doc](https://docs.vespa.ai/en/overview.html) (attention, ne pas se laisser impressionner par toute la technique) ou poser des questions à leur [chat-bot](https://search.vespa.ai/) (même remarque).\n",
    "\n",
    "Une instance Vespa tourne sur le serveur à l'adresse http://vespa:8080 . Pour y accéder facilement nous utiliserons le package Python PyVespa (voir [le doc](https://pyvespa.readthedocs.io/en/latest/index.html)) proposé par l'équipe Vespa :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9be68aff-7695-4ea2-827b-7b01c205de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application is up!\n"
     ]
    }
   ],
   "source": [
    "from vespa.application import Vespa\n",
    "import json\n",
    "\n",
    "vespa = Vespa(url=\"http://vespa\", port=8080)\n",
    "vespa.wait_for_application_up(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13c689de-807d-4531-825b-0cf7f7d762b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application is up!\n",
      "Réponse de Vespa:\n",
      "\n",
      "{\n",
      "  \"id\": \"toplevel\",\n",
      "  \"relevance\": 1.0,\n",
      "  \"fields\": {\n",
      "    \"totalCount\": 79\n",
      "  },\n",
      "  \"coverage\": {\n",
      "    \"coverage\": 100,\n",
      "    \"documents\": 959,\n",
      "    \"full\": true,\n",
      "    \"nodes\": 1,\n",
      "    \"results\": 1,\n",
      "    \"resultsFull\": 1\n",
      "  },\n",
      "  \"children\": [\n",
      "    {\n",
      "      \"id\": \"id:beer:beer::beer:4134\",\n",
      "      \"relevance\": 3.7397587588627377,\n",
      "      \"source\": \"beer_content\",\n",
      "      \"fields\": {\n",
      "        \"sddocname\": \"beer\",\n",
      "        \"documentid\": \"id:beer:beer::beer:4134\",\n",
      "        \"name\": \"Kalamazoo Stout\",\n",
      "        \"description_beer\": \"A full-bodied stout with plenty of roast flavor. Kalamazoo Stout is available year round, leading our vast portfolio of stouts.\",\n",
      "        \"brewery\": \"Bell's Brewery Inc.\",\n",
      "        \"address1\": \"8938 Krum Ave.\",\n",
      "        \"country\": \"United States\",\n",
      "        \"cat_name\": \"British Ale\",\n",
      "        \"style_name\": \"Sweet Stout\",\n",
      "        \"summaryfeatures\": {\n",
      "          \"bm25(brewery)\": 0.0,\n",
      "          \"bm25(description_beer)\": 3.7397587588627377,\n",
      "          \"length_of_descr\": 1.0,\n",
      "          \"vespa.summaryFeatures.cached\": 0.0\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"id:beer:beer::beer:3751\",\n",
      "      \"relevance\": 3.618319853732534,\n",
      "      \"source\": \"beer_content\",\n",
      "      \"fields\": {\n",
      "        \"sddocname\": \"beer\",\n",
      "        \"documentid\": \"id:beer:beer::beer:3751\",\n",
      "        \"name\": \"Oatmeal Stout\",\n",
      "        \"description_beer\": \"Tr\\u00c3\\u00b6egs Oatmeal Stout is our interpretation of the classic dry stout style. Dark and creamy with hints of chocolate and black currants, our Oatmeal Stout includes a healthy dose of Centennial and Chinook hops creating a unique stout perfect for the late Fall and Winter.\",\n",
      "        \"brewery\": \"Troegs Brewing\",\n",
      "        \"address1\": \"800 Paxton Street\",\n",
      "        \"country\": \"United States\",\n",
      "        \"cat_name\": \"North American Ale\",\n",
      "        \"style_name\": \"American-Style Stout\",\n",
      "        \"summaryfeatures\": {\n",
      "          \"bm25(brewery)\": 0.0,\n",
      "          \"bm25(description_beer)\": 3.618319853732534,\n",
      "          \"length_of_descr\": 1.0,\n",
      "          \"vespa.summaryFeatures.cached\": 0.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# requête simple\n",
    "resp = vespa.query(\n",
    "    {\n",
    "        \"yql\": \"select * from beer where userQuery()\", # <-- on dirait du SQL !\n",
    "        \"hits\": 2, # <-- nombre de résultats voulus\n",
    "        \"query\": \"stout\", # <-- query textuelle, nous verrons son usage après\n",
    "    }\n",
    ")\n",
    "print(\"Réponse de Vespa:\\n\")\n",
    "print(json.dumps(resp.json[\"root\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968d0f7-49cd-4174-868f-0c70f830e92f",
   "metadata": {},
   "source": [
    "Un index (Vespa ou ES) a besoin de connaître le schéma de data à indexer. Il s'agit de :\n",
    "- l'ensemble des attributs d'un document à indexer : nom, type (string, float, ...)\n",
    "- si nécessaire, la façon dont un champ doit être utilisés par Vespa lors de l'indexation : simple attribut, indexé par `posting list`, exploitable via BM25, affichable dans les réponses aux queries, etc ...\n",
    "\n",
    "Elastic nomme cela [mapping](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html), Vespa nomme cela la [schema](https://docs.vespa.ai/en/schemas.html). Exemple avec nos données montées sur Vespa\n",
    "```\n",
    "schema beer {\n",
    "    document beer {\n",
    "        field id type string {\n",
    "        }\n",
    "        field name type string {\n",
    "            indexing: index | summary\n",
    "        }\n",
    "        field description_beer type string {\n",
    "            indexing: index | summary | attribute\n",
    "            index: enable-bm25\n",
    "        }\n",
    "        field brewery type string {\n",
    "            indexing: index | summary\n",
    "            index: enable-bm25\n",
    "        }\n",
    "        field address1 type string {\n",
    "            indexing: index | summary | attribute\n",
    "        }\n",
    "        field description_brewery type string {\n",
    "            indexing: index\n",
    "            index: enable-bm25\n",
    "        }\n",
    "    [...]\n",
    "    }\n",
    "\n",
    "  [...]\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5289ff0-2268-45ce-9518-3eea01dfb25b",
   "metadata": {},
   "source": [
    "Vespa est très orienté recherche d'information et permet également de définir des façons de très précise le **score d'adéquation** à utiliser pour classer (ranker) les documents. Il s'agit d'une autre partie du schéma :\n",
    "```\n",
    "  [...]\n",
    "\n",
    "    rank-profile basic_bm25 {\n",
    "        first-phase {\n",
    "            expression {\n",
    "                bm25(name) + bm25(description_beer)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "  [...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e21ce-be01-440a-9140-c548d85655b9",
   "metadata": {},
   "source": [
    "# Uses cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196d8ff-9502-419a-a3e7-8ac3411003f5",
   "metadata": {},
   "source": [
    "## UC-1 : description data\n",
    "\n",
    "Attention, plus compliqué qu'en SQL. Voir les docs spécifiques\n",
    "- [doc spécifique Vespa sur le grouping](https://docs.vespa.ai/en/grouping.html)\n",
    "- [doc sur le SQL façon Vespa - YQL](https://docs.vespa.ai/en/vespa-cli#cheat-sheet)\n",
    "\n",
    "**Ne pas chercher à aller jusqu'au bout !!** Nous remarquerons assez vite que c'est galère avec Vespa\n",
    "\n",
    "- Q1: Combien y a-t-il de bières dans la DB ?\n",
    "- Q2: Top10 brasseries les plus représentées avec le nombre de bière par brasserie ?\n",
    "- Q3: Top10 des bières les plus fortes (ABV) en France ?\n",
    "- Q4: Par pays, nombre de brasseries qui proposent des bières de type `Porter` et ABV moyen de celles-ci ?\n",
    "- Q5: Mediane du nombre de bière par pays ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ceab508-cacb-457d-99b7-85b25bf17c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b83d3-ad59-49ec-b81b-7be6ab494327",
   "metadata": {},
   "source": [
    "# UC-2 : préparer un dataset de ranking \n",
    "\n",
    "Plusieurs problèmes pour résoudre ce use-case:\n",
    "- cf intro : un index ne peut pas faire de jointure \n",
    "- cf UC-1 : les grouping sont horribles à réaliser\n",
    "\n",
    "Conclusion : les index ne sont vraiment pas adaptés pour fabriquer des datasets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7544207-f8f6-4954-b8de-e59dcb4f537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b943ce-e976-4477-ba12-e80e8437286b",
   "metadata": {},
   "source": [
    "# UC-3 : récupérer les docs qui parlent d'un mot\n",
    "\n",
    "Peut-on utiliser Vespa pour réaliser un mini moteur de recherche ? \n",
    "\n",
    "**Rappel:** une configuration Vespa intègre la définition d'un **score d'adéquation** entre query et document ! Le `rank-profile` suivant existe sur l'instance Vespa utilisées :\n",
    "```\n",
    "  [...]\n",
    "\n",
    "    rank-profile rank-brewery-and-descr inherits root{\n",
    "        first-phase {\n",
    "            expression {\n",
    "                bm25(description_brewery) + bm25(description_beer)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "  [...]\n",
    "```\n",
    "\n",
    "**Question 1:** expliquer en 2 phrases comment le rank-profile `rank-brewery-and-descr` va agir.\n",
    "\n",
    "**Question 2:** pour différentes requêtes textuelles très simples à base de mot-clef, retrouver les bières qui semblent répondre à la demande :\n",
    "- trouver les bières ou les brasseries qui parlent de bières \"fine\"\n",
    "- idem pour \"juicy\"\n",
    "- idem pour \"genuine\"\n",
    "- idem pour les bières mâturées dans des \"oak cask\" (fûts en chêne) -> combien y en a-t-il ? $N_1$\n",
    "   - idem pour les bières qui évoquent uniquement \"cask\" -> combien y en a-t-il ? $N_{1,1}$\n",
    "   - idem pour celles ne parlant que de \"oak\" -> combien y en a-t-il ? $N_{1,2}$\n",
    "- idem pour les bières qui évoquent \"oak\" et \"cask\" -> combien y en a-t-il ? $N_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bd62802-b094-4195-98c6-e0bb0149a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc09e9d-5759-4242-b7bc-c01517cbfb20",
   "metadata": {},
   "source": [
    "# UC-4 : vectorisation des description des bières\n",
    "\n",
    "## Index et \"scrolling/visiting\"\n",
    "\n",
    "Les index ne sont \"pas faits\" pour manipuler la donnée qu'ils hébergent, néanmoins il existe plusieurs systèmes qui permettent à un code arbitraire de s'exécuter sur chaque document. Vespa nomme son système `visitor` ([doc](https://docs.vespa.ai/en/visiting.html)) et permet de \n",
    "- selectionner des documents à processer\n",
    "- dumper l'index en parallèle (et possiblement les modifier + update à la volée)\n",
    "- appliquer un code arbitraire à des documents (Nécessite le recours à Java pour expliciter l'opération :o )\n",
    "\n",
    "L'équivalent Elastic Search est le [scroll](https://www.elastic.co/guide/en/elasticsearch/guide/current/scroll.html).\n",
    "\n",
    "**Remarque:** on comprend vite qu'il n'est pas forcément simple de manipuler une donnée une fois qu'elle est indexée. Vespa étant très tourné vers le ML, il est toutefois possible de vectoriser des documents automatiquement lors de leur upsert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c1c2c-7a0e-418c-b180-069e2787232e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459c04bc-29c2-4c96-a2c5-078b8098ec52",
   "metadata": {},
   "source": [
    "# UC-5 : answer question in corpa\n",
    "\n",
    "**impossible en SQL**\n",
    "\n",
    "**Grandes lignes :** trouvons les documents qui répondent à une question. Exemple : à partir de la description vectorisée à UC-4 pour chaque bière, comment trouver les bières qui répondent à une description plus complète ? Exemple:\n",
    "- \"very bitter beer with smoky taste\"\n",
    "- \"fruity sour - balanced sourness\"\n",
    "- \"weird beer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe8a65-bb26-4ad3-8e04-aa108602eaa1",
   "metadata": {},
   "source": [
    "## Index vectoriel : NN et ANN, équivalent ML des index lexicaux\n",
    "Depuis ~2020, le ML permet de représenter des documents textuels par des vecteurs en grande dimension (appelés **embedding**) qui possèdent l'énorme propriété de traduire numériquement/vectoriellement l'information sémantique contenue dans les documents. De surcroit, ces embeddings peuvent se comparer algébriquement très simplement dans le sens où 2 embeddings \"proches\" (dans leur espace) correspondent à des objets proches (dans notre perception). Le uses-case 4 des TP précédent visait à obtenir de tels embeddings à partir d'un service externe.\n",
    "\n",
    "et les algorithmes *Nearest Neighbors* ou plus récemment *Approximated Nearest Neighbors*.\n",
    "### Recherche par plus proche voisins \n",
    "#### Algorithme Nearest Neighbors - NN\n",
    "\n",
    "Puisqu'il est possible de représenter (presque) tout document sous format embedding et que ces derniers ont la propriété d'être comparables entre eux, un nouveau type de recherche s'ouvre : recherche par embeddings les plus proche de l'embedding d'une query. Opérer une recherche à partir d'une query revient à trouver les *plus proches voisins* (Nearest Neighbors - NN) de l'embedding de la query parmi les embeddings de documents.\n",
    "\n",
    "Exemple en dimension 2 : les coordonnées GPS 2D d'une ville sont en quelque sort un embedding basique d'une ville. Trouver les 5 villes les plus proches de Nancy est simple : il suffit de cacluler les distances de Nancy à toutes les villes grâce à leurs coordonnées et de trouver les top5 distances les plus faibles.\n",
    "\n",
    "**Problème:** une telle recherche exhaustive implique $O(n^2)$ calculs où $n$ est le nombre de villes. Si $n=10^6$, le calcul devient difficile.\n",
    "\n",
    "#### Variante Approximative Nearest Neihbors - ANN\n",
    "\n",
    "**Solution proposée:** sachant qu'il est inutile de calculer la distance entre Nancy et Timbuktu ou New-York (celles-ci ne seront jamais dans le top5 proximité), il peut être intéressant de restreindre le champ de recherche afin de ne payer une recherche exhaustive en $O(n^2)$ que pour une poignée de villes qu'on sait déjà être \"proches\". Dans notre exemple, une recherche limitée au département de la ville cible et aux départements limitrophes suffit. \n",
    "\n",
    "Il s'agit d'un début de compréhension de la famille d'algorithmes Approximative Nearest Neihbors (ANN par la suite) qui permet de casser la complexité du problème de recherche de plus proches voisins en hierarchisant l'information. Cette hierarchisation se fait via une structure de donnée particulière ; l'implémentation la plus courante en 2024 est [Hierarchical Navigable Small World - HNSW](https://www.wikiwand.com/en/articles/HNSW_indexes).\n",
    "\n",
    "Remarque : l'algo qui traduit réellement la hierarchisation stricte est plutôt de la famille [K-d tree](https://www.wikiwand.com/en/articles/K-d_tree) mais il est inefficace pour des vecteurs de dimension $k=768+$ comme c'est le cas pour la plupart des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74b2ff-2bf8-40e7-a925-c5b73c4f8a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
