{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8af4d-c3fa-4d0f-9f2e-f7f4c4558a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# MySQL connection details\n",
    "mysql_host = 'mysql'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'rootpassword'\n",
    "mysql_database = 'workshop_db'\n",
    "\n",
    "# Create a connection to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=mysql_host,\n",
    "    user=mysql_user,\n",
    "    password=mysql_password,\n",
    "    database=mysql_database\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8947960-a31c-4c2d-96e2-365997d4d7b4",
   "metadata": {},
   "source": [
    "# UC-1 : description data\n",
    "\n",
    "- Q1: Combien y a-t-il de bières dans la DB ?\n",
    "- Q2: Top10 brasseries les plus représentées avec le nombre de bière par brasserie ?\n",
    "- Q3: Top10 des bières les plus fortes (ABV) en France ?\n",
    "- Q4: Par pays, nombre de brasseries qui proposent des bières de type `Porter` et ABV moyen de celles-ci ?\n",
    "- Q5: Mediane du nombre de bière par pays ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933fe39-0c86-44bc-aa35-50f6a0ff72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1d221-102b-4f3f-a6c5-65928327f088",
   "metadata": {},
   "source": [
    "# UC-2 : préparer un dataset de ranking \n",
    "Tout moteur de recherche/search-engine - **SE** - nécessite de la configuration ... beaucoup de configuration. Une des configuration très orientée \"data\" est le calcul que l'index doit opérer pour scorer chaque réponse possible face à une requête. L'apprentissage statistique de ce score s'appelle *Learning to Rank*  - **LTR** - et nécessite des connaissances poussées en machine learning. \n",
    "\n",
    "Cette tâche LTR se base sur les *feedbacks implicites* des utilisateurs face au moteur de recherche. Commençons par un exemple. Quand vous cherchez un objet sur LeBonCoin, vous laissez plusieurs informations *implicites* sur votre perception des résultats proposés : les item sur lesquels vous avez cliqués bien sûr mais également ceux que vous avez probablement *vu* sans cliquer dessus ... Ces \"vues sans clics\" sont une précieuse information implicite sur les jugement que vous avez porté aux résultats proposés. Pour ce TP nous nous limiterons à ce concept de \"vu x click\" mais il est possible d'aller plus loin (dwell-time, hierarchisation des interactions explicites, ...). \n",
    "\n",
    "On appelle *Search Engine Results Page* - **SERP** - la liste des résultats classés par un SE. Un document qui figure dans les résulats d'une recherche a donc une position (son rang) au sein de la **SERP**.\n",
    "\n",
    "Exemple, où :\n",
    "- `query` est la recherche réalisée par un user et qui a débouché sur une SERP\n",
    "- `clicked_id` : l'id de la bière cliquée par le user\n",
    "- `user_id` l'id de l'utilisateur (simplifions en disant que c'est même l'id d'une recherche) : permet de retrouver tous les résultats proposés dans **une** recherche\n",
    "- `id_in_serp` : l'id d'une bière figurant dans la SERP\n",
    "- `pos_in_serp` : la position/le rang de la bière `id_in_serp` dans la SERP issue de la recherche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8bdc2-f9f2-457f-a802-450612682861",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"SELECT * FROM `beers_feedback` ORDER BY RAND() LIMIT 5 ;\"\n",
    "pd.read_sql_query(q, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a3bed-089c-42fd-a165-8c891b2f49ac",
   "metadata": {},
   "source": [
    "Un travail préliminaire au LTR est la constitution d'un dataset qui permet d'aggréger ces feedbacks laissés par tous les utilisateurs ayant réalisé la même query. Chacun a vu et cliqué selon ses propres impressions de pertinence et il convient de \"moyenner\" tout cela pour obtenir des appréciations globales. L'objectif d'un tel dataset est de pouvoir lister des exemples de triplets `(query, document, note)` qui permet de savoir que face à une *query* `milky stout low bitterness`, un *document* `Super bitter beer brewed with organic roasted barley and chocolate` aura une pertinence de *1/4* (arbitraire). \n",
    "\n",
    "Implémenter le modèle d'agrégation de feedback \"cascade model\" [1] (pour la culture, **inutile d'avoir lu l'article** pour le TD) qui propose une approche pragmatique pour obtenir ces données. La méthode est la suivante :\n",
    "- pour chaque recherche utilisateur:\n",
    "    - étudier la position de l'id cliqué dans la SERP - soit `clicked_pos_in_serp` cette information\n",
    "    - Considérer que tout doc situés \"au-dessus dans la SERP\" (càd quand `pos_in_serp <= clicked_pos_in_serp`) avait été vu par l'utilisateur\n",
    "    - Récapituler tous ces documents \"vus et cliqués\" et \"vus mais pas cliqués\"\n",
    "- Pour chaque recherche et bière cliquée (`clicked_id`), calculer la \"probabilité de clic sachant qu'elle a été vue\", càd le nombre de fois qu'elle a été cliquée divisé par le nombre de fois où elle a été vue\n",
    "\n",
    "\n",
    "[1] https://dl.acm.org/doi/abs/10.1145/1341531.1341545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20e7bf-fda3-4ec4-9691-d4bed9ae960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aee246-c7c4-4be5-a9e4-d6fa922f3a74",
   "metadata": {},
   "source": [
    "# UC-3 : récupérer les docs qui parlent d'un mot\n",
    "\n",
    "Peut-on utiliser SQL pour réaliser un mini moteur de recherche ? Pour différentes requêtes (`query` en anglais) textuelles très simples à base de mot-clef, retrouver les bières qui semblent répondre à la demande. Exemples :\n",
    "- trouver les bières ou les brasseries qui parlent de bières \"fine\"\n",
    "- idem pour \"juicy\"\n",
    "- idem pour \"genuine\"\n",
    "- idem pour les bières mâturées dans des \"oak cask\" (fûts en chêne) -> combien y en a-t-il ? $N_1$\n",
    "   - idem pour les bières qui évoquent uniquement \"cask\" -> combien y en a-t-il ? $N_{1,1}$\n",
    "   - idem pour celles ne parlant que de \"oak\" -> combien y en a-t-il ? $N_{1,2}$\n",
    "- idem pour les bières qui évoquent \"oak\" et \"cask\" -> combien y en a-t-il ? $N_{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab6df7-09b2-43ea-a7af-7124432fadfb",
   "metadata": {},
   "source": [
    "# UC-4 : vectorisation des description des bières\n",
    "Préparer le recours à un service de vectorisation qui permettra de convertir la connaissance sur une bière en un vecteur numérique. Ce vecteur permet de sythétiser mathématiquement l'information disponible sur une bière et sa brasserie et pourra être réutilisé plus tard dans un moteur de recherche.\n",
    "à faire :\n",
    "- Préparer une description la plus complète possible pour chaque bière\n",
    "- envoyer ces descriptions une à une via un appel HTTP sur Jina (voir instruction plus bas)\n",
    "\n",
    "**Découpez le travail** : chacun travaillera sur un sous-ensemble de bières selon l'`id` de chaque bière `beers.id`. \n",
    "Vous êtes 12, je propose donc la répartition suivante :\n",
    "- ADAM.LUCAS --> s'occuper des `beers.id` égaux à 0 modulo 12\n",
    "- ALIEINIK.OLHA --> s'occuper des `beers.id` égaux à 1 modulo 12\n",
    "- ARNOUT.FABRICE --> s'occuper des `beers.id` égaux à 2 modulo 12\n",
    "- BEDIER.DORIANE --> s'occuper des `beers.id` égaux à 3 modulo 12\n",
    "- CASTRO.MOUCHERON --> s'occuper des `beers.id` égaux à 4 modulo 12\n",
    "- COLIN.KEVIN --> s'occuper des `beers.id` égaux à 5 modulo 12\n",
    "- FRASELLE.NADEGE --> s'occuper des `beers.id` égaux à 6 modulo 12\n",
    "- KUKSA.OLEKSANDRA --> s'occuper des `beers.id` égaux à 7 modulo 12\n",
    "- LOPES.VAZ.ALEXIS --> s'occuper des `beers.id` égaux à 8 modulo 12\n",
    "- REITER.ROMAIN --> s'occuper des `beers.id` égaux à 9 modulo 12\n",
    "- RICHIER.MARCUS --> s'occuper des `beers.id` égaux à 10 modulo 12\n",
    "- VINOT.MATHIEU --> s'occuper des `beers.id` égaux à 11 modulo 12\n",
    "\n",
    "## Service de vectorisation Jina\n",
    "Nous allons faire appel à un service de vectorisation externe [https://jina.ai](https://jina.ai) qui propose gratuitement 1M token de vectorisation. \n",
    "Quand vous voudrez vectoriser un texte, suivez la doc de [https://jina.ai/embeddings/](https://jina.ai/embeddings/). \n",
    "\n",
    "Nous utiliserons **TOUS le MÊME modèle d'embedding** : `jina-embeddings-v2-base-en` ! Faites donc attention à appeler le bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05655a5f-a370-4a70-94ff-4350ade48d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354efb68-da97-4ea6-9367-6c3e6f2f87ee",
   "metadata": {},
   "source": [
    "Essayons de construire d'avoir tous le même schéma de texte à vectoriser :\n",
    "`the beer BEER_NAME from brewery BREWERY_NAME (BREWERY_DESCRIPTION) is defined as BEER_DESCRIPTION. Spec of the beer are: ABV=ABV_VALUE, IBU=IBU_VALUE, SRM=SRM_VALUE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f627f-631e-4748-ad08-f76581656d58",
   "metadata": {},
   "source": [
    "#### Instructions pour appeler le service Jina\n",
    "En plus de la doc sur leur site, voici un snippet de code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b09324-7f15-4e5f-a855-79973a7f9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "EMBEDDING_NAME = \"jina-embeddings-v2-base-en\"\n",
    "url = 'https://api.jina.ai/v1/embeddings'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer jina_85ba1ab9e5ff4017b3d216ebb8734f27xzJ9WyoYBFwqks9lOaNLHryw_Yyz'\n",
    "}\n",
    "\n",
    "sentences_to_vec = [\"Hi i'm a student at Université de Lorraine\", \"This is big data workshop\"]\n",
    "data = {\n",
    "    'model': EMBEDDING_NAME,\n",
    "    'normalized': True,\n",
    "    'embedding_type': 'float',\n",
    "    'input': sentences_to_vec\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218022c5-ee36-4a5c-a34e-67a8a5888006",
   "metadata": {},
   "source": [
    "Exemple avec mon propre code pour appeler Jina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83d2f2-76b7-4ba9-9523-a8a75e1d45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class JinaEmbedder:\n",
    "    \n",
    "    URL = 'https://api.jina.ai/v1/embeddings'\n",
    "    EMBEDDING_NAME = \"jina-embeddings-v2-base-en\"\n",
    "    bearer_token = 'Bearer jina_85ba1ab9e5ff4017b3d216ebb8734f27xzJ9WyoYBFwqks9lOaNLHryw_Yyz'\n",
    "\n",
    "    @staticmethod\n",
    "    def http_json_to_vec(http_json: dict):\n",
    "        return np.array(\n",
    "            [\n",
    "                sentence[\"embedding\"]\n",
    "                for sentence in http_json[\"data\"]\n",
    "            ]\n",
    "        )        \n",
    "\n",
    "    @classmethod\n",
    "    def embed(cls, str_to_vectorize: List[str] | str) -> np.ndarray:\n",
    "        if isinstance(str_to_vectorize, str):\n",
    "            str_to_vectorize = [str_to_vectorize]\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': cls.bearer_token\n",
    "        }\n",
    "        data = {\n",
    "            'model': cls.EMBEDDING_NAME,\n",
    "            'normalized': True,\n",
    "            'embedding_type': 'float',\n",
    "            'input': str_to_vectorize\n",
    "        }\n",
    "        \n",
    "        response = requests.post(cls.URL, headers=headers, json=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        return JinaEmbedder.http_json_to_vec(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be4218-9b92-4a55-b3a3-7315104e4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3fc3d",
   "metadata": {},
   "source": [
    "# UC-5 : answer question in corpa\n",
    "\n",
    "**impossible en SQL**\n",
    "\n",
    "**Grandes lignes :** trouvons les documents qui répondent à une question. Exemple : à partir de la description vectorisée à UC-4 pour chaque bière, comment trouver les bières qui répondent à une description plus complète ? Exemple:\n",
    "- \"very bitter beer with smoky taste\"\n",
    "- \"fruity sour - balanced sourness\"\n",
    "- \"weird beer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74fa85e-c590-4511-992c-4bdeb85cbd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
