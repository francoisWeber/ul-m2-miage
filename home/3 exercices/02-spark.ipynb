{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4184713b-3d12-4e5b-abc8-d9b85922f01e",
   "metadata": {},
   "source": [
    "# Intro to Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806be423-194a-4a2e-8403-2435353e5c3e",
   "metadata": {},
   "source": [
    "**Spark** est un système de calcul hautement parallélisé :\n",
    "- au niveau du stockage : la data est fragmentée, dupliquée, répartie sur un nombre quelconque de disques/servers\n",
    "- au niveau du calcul : les calculs s'exécutent en parallèle sur plusieurs machines, chacune sur sa portion de data\n",
    "\n",
    "Spark en tant que tel est un framework qui a des implémentation dans plusieurs langages :\n",
    "- Python via PySpark (ce qe nous utiliserons)\n",
    "- Scala\n",
    "- R\n",
    "- Java\n",
    "\n",
    "## Quelques informations en vrac sur Spark\n",
    "### Hardware\n",
    "- Spark peut s'installer sur un grand nombre de machines situées dans un même réseau. Elles pourront ensuite se reconnaître et collaborer. 1 unité de calcul = 1 noeud.\n",
    "- Spark fonctionne sur le mode master/worker : un noeud est désigné `master` et jouera le rôle de chef d'orchestre pour que les autres noeuds `workers` exécutent les tâches dans le bon ordre\n",
    "- Les noeuds Spark communiquent énormément entre eux pour s'échanger des informations et surtout des données\n",
    "\n",
    "### Software\n",
    "- Un code Spark / PySpark doit utiliser les primitives Spark pour que tout s'exécute selon la logique Spark\n",
    "- Le code pyspark est transmis au noeud `master` qui le lit et prépare l'orchestration des calculs selon les `workers` qu'il a à disposition. Seuls les `workers` manipuleront la donnée (sauf exception)\n",
    "- Spark est *lazy* : `master` ne lance réellement aucun calcul tant qu'il n'a pas lu d'opération impliquant l'affichage ou l'écriture des résultats\n",
    "- Corrolaire du *lazy* : sans précaution, Spark peut répéter plusieurs fois les mêmes calculs ... Exemple avec 2 chaînes de transformation data `A -> B -> C -> D` suivi de `A -> B -> E`. Les étapes intermédiaires `A -> B` sont identiques mais pour calculer `D` et `E`, Spark risque de les exécuter 2 fois. Apprendre à manipuler les méthodes [cache](https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.cache.html?highlight=cache) !\n",
    "\n",
    "### Framework\n",
    "- Spark se base sur des `DataFrame` très proches en terme d'utilisation des `pandas.DataFrame` donc pas de panique :)\n",
    "- Spark gère tout ce que sait gérer SQL mais part de fichiers plats (ici CSV) : join, select, etc ...\n",
    "- PySpark permet de gérer tout ces concepts avec la facilité d'accès du Python\n",
    "- PySpark est TRÈS typé et a besoin de connaître les types de chaque colonne manipulées\n",
    "\n",
    "### Organisation du calcul\n",
    "En informatique, à chaque architecture ses optimisations :\n",
    "- en local sur 1 CPU, un calcul possède peu d'optimisation : simple et linéaire, possiblement async\n",
    "- en local sur multi CPU, un calcul doit être prévu pour paralléliser les exécutions sur plusieurs coeurs physiques\n",
    "- en local sur mono/multi GPU, un calcul doit être hautement parallélisable, découpable en tranche de data qui tiennent en GPU-RAM\n",
    "- en multi machine multi GPU, idem que plus haut avec bande passante importante entre machine pour échange d'information\n",
    "\n",
    "... Spark gère le multi machine, multi CPU, multi RAM, multi disque : calculs hautement parallélisés grâce à la magie de Spark, data échangées au mieux entre machine (possiblement avec l'aide humaine).\n",
    "__Spark est toujours prêt à gérer un contexte d'exécution très complexe__ => il faut s'attendre à beaucoup d'overhead sur des cas simples\n",
    "\n",
    "## À retenir\n",
    "\n",
    "1. Spark et son implémentation PySpark sont très puissant car gèrent un parallélisme quasi infini et réglable à 100%\n",
    "2. PySpark a un coût d'entrée pour se couler dans le moule Spark mais permet de réaliser des opérations très complexes avec la simplicité du Python\n",
    "\n",
    "## Exemple de code Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f318386f-71ef-44ec-aaf9-160ecd6ff0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ea6256-c381-4264-99b8-8987b21e8062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/13 12:22:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize PySpark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JupyterHub PySpark Example\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "# /!\\ Tout se fera à partir de cet object magique `spark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fccced-12e3-4a36-a9d4-7884eab014ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     Name|Value|\n",
      "+---------+-----+\n",
      "|    Alice|    1|\n",
      "|      Bob|    2|\n",
      "|Catherine|    3|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Catherine\", 3)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Value\"])\n",
    "\n",
    "# Show the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0328d481-2517-43d6-af84-935714cc9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "365084ed-4817-426d-919d-13f827892be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='1', brewery_id='812', name='Hocus Pocus', cat_id='11', style_id='116', abv='4.5', ibu='0', srm='0', upc='0', filepath=None, descript='Our take on a classic summer ale.  A toast to weeds, rays, and summer haze.  A light, crisp ale for mowing lawns, hitting lazy fly balls, and communing with nature, Hocus Pocus is offered up as a summer sacrifice to clodless days.', add_user=None, last_mod=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beers = spark.read.csv(\"/datasets/csv/beers.csv\", header=True)\n",
    "df_beers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5194190e-50b3-4e2d-a44c-24ded27a9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name| reverse_capitalized|\n",
      "+--------------------+--------------------+\n",
      "|         Hocus Pocus|         SUCOP SUCOH|\n",
      "| 2010-07-22 20:00:20| 02:00:02 22-70-0102|\n",
      "|   Grimbergen Blonde|   EDNOLB NEGREBMIRG|\n",
      "|Widdershins Barle...|ENIWYELRAB SNIHSR...|\n",
      "|             Lucifer|             REFICUL|\n",
      "|              Bitter|              RETTIB|\n",
      "|       Winter Warmer|       REMRAW RETNIW|\n",
      "|Winter Welcome 20...|8002-7002 EMOCLEW...|\n",
      "|       Oatmeal Stout|       TUOTS LAEMTAO|\n",
      "|     Espresso Porter|     RETROP OSSERPSE|\n",
      "|     Chocolate Stout|     TUOTS ETALOCOHC|\n",
      "|Hitachino Nest Re...|WERB REGNIG LAER ...|\n",
      "|         JuJu Ginger|         REGNIG UJUJ|\n",
      "|      The Kidd Lager|      REGAL DDIK EHT|\n",
      "|      Imperial Stout|      TUOTS LAIREPMI|\n",
      "|Oak-Aged Belgian ...|LEPIRT NAIGLEB DE...|\n",
      "|         Ultrablonde|         EDNOLBARTLU|\n",
      "|  Wiesen Edel Weisse|  ESSIEW LEDE NESEIW|\n",
      "|    Old Foghorn 2001|    1002 NROHGOF DLO|\n",
      "|           Framboise|           ESIOBMARF|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define a specific funtion to map beer names\n",
    "@F.udf(returnType=StringType())\n",
    "def revert_cap_name(name: str):\n",
    "    return name[::-1].upper()\n",
    "\n",
    "\n",
    "df_beers.withColumn(\"reverse_capitalized\", revert_cap_name(F.col(\"name\"))).select(\"name\", \"reverse_capitalized\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25580a-421d-41c6-bdb8-6ebe81a4b39b",
   "metadata": {},
   "source": [
    "## Observations\n",
    "Que remarque-t-on tout de suite ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672354a-2827-42fc-a265-fcedd0e8affc",
   "metadata": {},
   "source": [
    "# Uses cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19828ca-a8ba-4727-8258-b748ce8afb83",
   "metadata": {},
   "source": [
    "# UC-1 : description data\n",
    "\n",
    "- Q1: Combien y a-t-il de bières dans la DB ?\n",
    "- Q2: Top10 brasseries les plus représentées avec le nombre de bière par brasserie ?\n",
    "- Q3: Top10 des bières les plus fortes (ABV) en France ?\n",
    "- Q4: Par pays, nombre de brasseries qui proposent des bières de type `Porter` et ABV moyen de celles-ci ?\n",
    "- Q5: Mediane du nombre de bière par pays ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d79a3df-f2c8-42aa-b175-edb4269b945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers = spark.read.csv(\"/datasets/csv/beers.csv\", header=True)\n",
    "df_breweries = spark.read.csv(\"/datasets/csv/breweries.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14582ac5-f3a8-4ba6-b4e5-16c354d33db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 7060 dans la DB\n",
      "CPU times: user 1.52 ms, sys: 211 μs, total: 1.73 ms\n",
      "Wall time: 607 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "n_beers = df_beers.count()\n",
    "print(f\"Q1: {n_beers} dans la DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e49de9-688e-42ce-8599-a50fa82a89bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2\n",
      "+--------------+-----+\n",
      "|       country|count|\n",
      "+--------------+-----+\n",
      "| United States| 4552|\n",
      "|       Belgium|  331|\n",
      "|       Germany|  302|\n",
      "|United Kingdom|  210|\n",
      "|        Canada|  156|\n",
      "|   Netherlands|   29|\n",
      "|   Switzerland|   25|\n",
      "|       Austria|   25|\n",
      "|     Australia|   24|\n",
      "|        Norway|   22|\n",
      "+--------------+-----+\n",
      "\n",
      "CPU times: user 5.99 ms, sys: 0 ns, total: 5.99 ms\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Q2\")\n",
    "dd = (df_beers\n",
    "      .join(df_breweries, on=df_beers.brewery_id == df_breweries.id)\n",
    "      .groupby(\"country\")\n",
    "      .count()\n",
    "      .sort(F.col(\"count\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d869dd-b1a4-4dda-b5b1-e0d8a050cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/13 12:22:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|                name|abv_float|country|\n",
      "+--------------------+---------+-------+\n",
      "|           Belzebuth|     13.0| France|\n",
      "|Gavroche French R...|      8.5| France|\n",
      "|             3 Monts|      8.5| France|\n",
      "|                Yeti|      8.0| France|\n",
      "|      Jenlain Blonde|      7.5| France|\n",
      "|              Blonde|      7.5| France|\n",
      "|   Les Sans Culottes|      7.0| France|\n",
      "|           Framboise|      6.0| France|\n",
      "|Jenlain St Druon ...|      6.0| France|\n",
      "|Castelain St.Aman...|      5.9| France|\n",
      "+--------------------+---------+-------+\n",
      "\n",
      "CPU times: user 0 ns, sys: 13.3 ms, total: 13.3 ms\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Q3\n",
    "\n",
    "@F.udf(returnType=FloatType())\n",
    "def safe_cast_to_float(str_float: str):\n",
    "    return float(str_float)\n",
    "\n",
    "df_beers_brewers = (\n",
    "    df_beers\n",
    "    .join(df_breweries.withColumnRenamed(\"name\", \"brewer_name\"), on=df_beers.brewery_id == df_breweries.id)\n",
    ").cache()\n",
    "\n",
    "print(\"Q3\")\n",
    "dd = (df_beers_brewers\n",
    "      .filter(F.col(\"country\") == F.lit(\"France\"))\n",
    "      .withColumn(\"abv_float\", safe_cast_to_float(F.col(\"abv\")))\n",
    "      .sort(F.col(\"abv_float\").desc())\n",
    "      .select([\"name\", \"abv_float\", \"country\"])\n",
    "      .limit(10)\n",
    ")\n",
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2592486f-5350-4da7-bca6-3188c087d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4\n",
      "+--------------+------------------+----------------------+\n",
      "|       country|           avg_abv|n_brewer_having_porter|\n",
      "+--------------+------------------+----------------------+\n",
      "|        Russia|               7.0|                     1|\n",
      "|        Sweden|               5.5|                     1|\n",
      "|       Germany| 7.099999904632568|                     1|\n",
      "| United States|2.3305555541291194|                   216|\n",
      "|     Lithuania| 6.800000190734863|                     1|\n",
      "|        Norway|               7.0|                     1|\n",
      "|       Denmark|               8.0|                     1|\n",
      "|   Switzerland|               4.5|                     1|\n",
      "|        Canada|               0.0|                     5|\n",
      "|Czech Republic|               8.0|                     1|\n",
      "|         Japan|               0.0|                     1|\n",
      "|        Poland| 8.300000190734863|                     1|\n",
      "|     Australia|               0.0|                     1|\n",
      "|United Kingdom|3.9500000136239186|                    13|\n",
      "+--------------+------------------+----------------------+\n",
      "\n",
      "CPU times: user 7.94 ms, sys: 4.5 ms, total: 12.4 ms\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Q4\")\n",
    "df_style = spark.read.csv(\"/datasets/csv/styles.csv\", header=True)\n",
    "target_style_id = df_style.filter(F.lower(F.col(\"style_name\")) == \"porter\").select(F.col(\"id\").alias(\"style_id\"))\n",
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .join(target_style_id, how=\"inner\", on=\"style_id\")\n",
    "    .withColumn(\"abv_float\", safe_cast_to_float(F.col(\"abv\")))\n",
    "    .select([\"name\", \"brewer_name\", \"abv_float\", \"country\"])\n",
    "    .groupby(\"country\")\n",
    "    .agg(F.avg(\"abv_float\").alias(\"avg_abv\"), F.countDistinct(\"brewer_name\").alias(\"n_brewer_having_porter\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d25f07-0333-4845-a781-b8e023ec2481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, count: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .groupby(\"country\")\n",
    "    .count()\n",
    ")\n",
    "dd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a391c9-33e1-48f4-9afe-4d3c727261cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:============================================>         (164 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: 3.0\n",
      "CPU times: user 9.93 ms, sys: 4.83 ms, total: 14.8 ms\n",
      "Wall time: 4.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Q5:\", dd.agg(F.median(\"count\")).first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfed943-eba2-4563-9de9-adcc889c53a7",
   "metadata": {},
   "source": [
    "Voyons la différence de vitesse avec une version Numpy local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ba7215-1d6a-4b18-b73d-ebd13eb00278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "obs = dd.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c52c1b-2e34-4cf7-b8cd-a20aca15be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 version local via Numpy: 3.0\n",
      "CPU times: user 263 μs, sys: 41 μs, total: 304 μs\n",
      "Wall time: 295 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Q5 version local via Numpy:\", np.median(obs[\"count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82d2e7-274a-49e8-bb1f-5d491bec2609",
   "metadata": {},
   "source": [
    "# UC-2 : préparer un dataset de ranking \n",
    "Tout moteur de recherche/search-engine - **SE** - nécessite de la configuration ... beaucoup de configuration. Une des configuration très orientée \"data\" est le calcul que l'index doit opérer pour scorer chaque réponse possible face à une requête. L'apprentissage statistique de ce score s'appelle *Learning to Rank*  - **LTR** - et nécessite des connaissances poussées en machine learning. \n",
    "\n",
    "Cette tâche LTR se base sur les *feedbacks implicites* des utilisateurs face au moteur de recherche. Commençons par un exemple. Quand vous cherchez un objet sur LeBonCoin, vous laissez plusieurs informations *implicites* sur votre perception des résultats proposés : les item sur lesquels vous avez cliqués bien sûr mais également ceux que vous avez probablement *vu* sans cliquer dessus ... Ces \"vues sans clics\" sont une précieuse information implicite sur les jugement que vous avez porté aux résultats proposés. Pour ce TP nous nous limiterons à ce concept de \"vu x click\" mais il est possible d'aller plus loin (dwell-time, hierarchisation des interactions explicites, ...). \n",
    "\n",
    "On appelle *Search Engine Results Page* - **SERP** - la liste des résultats classés par un SE. Un document qui figure dans les résulats d'une recherche a donc une position (son rang) au sein de la **SERP**.\n",
    "\n",
    "Exemple, où :\n",
    "- `query` est la recherche réalisée par un user et qui a débouché sur une SERP\n",
    "- `clicked_id` : l'id de la bière cliquée par le user\n",
    "- `user_id` l'id de l'utilisateur (simplifions en disant que c'est même l'id d'une recherche) : permet de retrouver tous les résultats proposés dans **une** recherche\n",
    "- `id_in_serp` : l'id d'une bière figurant dans la SERP\n",
    "- `pos_in_serp` : la position/le rang de la bière `id_in_serp` dans la SERP issue de la recherche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2153f482-d334-4f46-8134-d25dfe0643a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+----------+-----------+\n",
      "|      query|clicked_id|             user_id|id_in_serp|pos_in_serp|\n",
      "+-----------+----------+--------------------+----------+-----------+\n",
      "|fruity sour|      4442|ecfce536-7fc5-11e...|      4442|          1|\n",
      "|fruity sour|      4442|ecfce536-7fc5-11e...|       475|          2|\n",
      "|fruity sour|      4442|ecfce536-7fc5-11e...|       481|          3|\n",
      "+-----------+----------+--------------------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pref = spark.read.csv(\"/datasets/beers_feedback.csv\", header=True, inferSchema=True)\n",
    "df_pref.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28882f0-de9a-4fbc-97c5-a37864103477",
   "metadata": {},
   "source": [
    "Un travail préliminaire au LTR est la constitution d'un dataset qui permet d'aggréger ces feedbacks laissés par tous les utilisateurs ayant réalisé la même query. Chacun a vu et cliqué selon ses propres impressions de pertinence et il convient de \"moyenner\" tout cela pour obtenir des appréciations globales. L'objectif d'un tel dataset est de pouvoir lister des exemples de triplets `(query, document, note)` qui permet de savoir que face à une *query* `milky stout low bitterness`, un *document* `Super bitter beer brewed with organic roasted barley and chocolate` aura une pertinence de *1/4* (arbitraire). \n",
    "\n",
    "Implémenter le modèle d'agrégation de feedback \"cascade model\" [1] (pour la culture, **inutile d'avoir lu l'article** pour le TD) qui propose une approche pragmatique pour obtenir ces données. La méthode est la suivante :\n",
    "- pour chaque recherche utilisateur:\n",
    "    - étudier la position de l'id cliqué dans la SERP - soit `clicked_pos_in_serp` cette information\n",
    "    - Considérer que tout doc situés \"au-dessus dans la SERP\" (càd quand `pos_in_serp <= clicked_pos_in_serp`) avait été vu par l'utilisateur\n",
    "    - Récapituler tous ces documents \"vus et cliqués\" et \"vus mais pas cliqués\"\n",
    "- Pour chaque recherche et bière cliquée (`clicked_id`), calculer la \"probabilité de clic sachant qu'elle a été vue\", càd le nombre de fois qu'elle a été cliquée divisé par le nombre de fois où elle a été vue\n",
    "\n",
    "\n",
    "[1] https://dl.acm.org/doi/abs/10.1145/1341531.1341545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3945da0-7065-4872-a82e-54df5b84f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1646b-d653-496a-be37-0d425c1abadd",
   "metadata": {},
   "source": [
    "# UC-3 : récupérer les docs qui parlent d'une query\n",
    "\n",
    "Peut-on utiliser SQL pour réaliser un mini moteur de recherche ? Pour différentes requêtes (`query` en anglais) textuelles, retrouver les bières qui semblent répondre à la demande. Exemples :\n",
    "- trouver les bières ou les brasseries qui parlent de bières \"fine\"\n",
    "- idem pour \"juicy\"\n",
    "- idem pour \"genuine\"\n",
    "- idem pour les bières mâturées dans des \"oak cask\" (fûts en chêne) -> combien y en a-t-il ? $N_1$\n",
    "   - idem pour les bières qui évoquent uniquement \"cask\" -> combien y en a-t-il ? $N_{1,1}$\n",
    "   - idem pour celles ne parlant que de \"oak\" -> combien y en a-t-il ? $N_{1,2}$\n",
    "- idem pour les bières qui évoquent \"oak\" et \"cask\" -> combien y en a-t-il ? $N_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "675fd4dd-8135-4f27-a0cb-2c8baeb1df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d942b-9c0d-46b5-afa1-b46dfcb4393f",
   "metadata": {},
   "source": [
    "# UC-4 : vectorisation des description des bières\n",
    "Préparer le recours à un service de vectorisation qui permettra de convertir la connaissance sur une bière en un vecteur numérique. Ce vecteur permet de sythétiser mathématiquement l'information disponible sur une bière et sa brasserie et pourra être réutilisé plus tard dans un moteur de recherche.\n",
    "à faire :\n",
    "- Préparer une description la plus complète possible pour chaque bière\n",
    "- envoyer ces descriptions une à une via un appel HTTP sur Jina (voir instruction plus bas)\n",
    "\n",
    "**Découpez le travail** : chacun travaillera sur un sous-ensemble de bières selon l'`id` de chaque bière `beers.id`. \n",
    "Vous êtes 12, je propose donc la répartition suivante :\n",
    "- ADAM.LUCAS --> s'occuper des `beers.id` égaux à 0 modulo 12\n",
    "- ALIEINIK.OLHA --> s'occuper des `beers.id` égaux à 1 modulo 12\n",
    "- ARNOUT.FABRICE --> s'occuper des `beers.id` égaux à 2 modulo 12\n",
    "- BEDIER.DORIANE --> s'occuper des `beers.id` égaux à 3 modulo 12\n",
    "- CASTRO.MOUCHERON --> s'occuper des `beers.id` égaux à 4 modulo 12\n",
    "- COLIN.KEVIN --> s'occuper des `beers.id` égaux à 5 modulo 12\n",
    "- FRASELLE.NADEGE --> s'occuper des `beers.id` égaux à 6 modulo 12\n",
    "- KUKSA.OLEKSANDRA --> s'occuper des `beers.id` égaux à 7 modulo 12\n",
    "- LOPES.VAZ.ALEXIS --> s'occuper des `beers.id` égaux à 8 modulo 12\n",
    "- REITER.ROMAIN --> s'occuper des `beers.id` égaux à 9 modulo 12\n",
    "- RICHIER.MARCUS --> s'occuper des `beers.id` égaux à 10 modulo 12\n",
    "- VINOT.MATHIEU --> s'occuper des `beers.id` égaux à 11 modulo 12\n",
    "\n",
    "## Service de vectorisation Jina\n",
    "Nous allons faire appel à un service de vectorisation externe [https://jina.ai](https://jina.ai) qui propose gratuitement 1M token de vectorisation. \n",
    "Quand vous voudrez vectoriser un texte, suivez la doc de [https://jina.ai/embeddings/](https://jina.ai/embeddings/). \n",
    "\n",
    "Nous utiliserons **TOUS le MÊME modèle d'embedding** : `jina-embeddings-v2-base-en` ! Faites donc attention à appeler le bon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1cfee-f1dc-4842-bd80-c30f4d1c57b3",
   "metadata": {},
   "source": [
    "Essayons de construire d'avoir tous le même schéma de texte à vectoriser :\n",
    "`the beer BEER_NAME from brewery BREWERY_NAME (BREWERY_DESCRIPTION) is defined as BEER_DESCRIPTION. Spec of the beer are: ABV=ABV_VALUE, IBU=IBU_VALUE, SRM=SRM_VALUE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ee4db-2551-41b8-aa2c-e62e00f29f6d",
   "metadata": {},
   "source": [
    "#### Instructions pour appeler le service Jina\n",
    "En plus de la doc sur leur site, voici un snippet de code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b09324-7f15-4e5f-a855-79973a7f9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "EMBEDDING_NAME = \"jina-embeddings-v2-base-en\"\n",
    "url = 'https://api.jina.ai/v1/embeddings'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer jina_85ba1ab9e5ff4017b3d216ebb8734f27xzJ9WyoYBFwqks9lOaNLHryw_Yyz'\n",
    "}\n",
    "\n",
    "sentences_to_vec = [\"Hi i'm a student at Université de Lorraine\", \"This is big data workshop\"]\n",
    "data = {\n",
    "    'model': EMBEDDING_NAME,\n",
    "    'normalized': True,\n",
    "    'embedding_type': 'float',\n",
    "    'input': sentences_to_vec\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "810d106a-bcd8-4d46-9200-c7d6bd88797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b1fbe30-6613-42c6-9029-ab03f75e1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=StringType())\n",
    "def craft_to_txt_vectorize(beer_name, brewer_name, beer_text, brewer_text, abv, ibu, srm):\n",
    "    beer_name = beer_name if beer_name else \"\"\n",
    "    brewer_name = brewer_name if brewer_name else \"\"\n",
    "    beer_text = beer_text if beer_text else \"\"\n",
    "    brewer_text = brewer_text if brewer_text else \"\"\n",
    "    abv = abv if abv else \"\"\n",
    "    ibu = ibu if ibu else \"\"\n",
    "    srm = srm if srm else \"\"\n",
    "    to_vec = f\"the beer {beer_name} from brewery {brewer_name} ({brewer_text}) is defined as {beer_text}.\"\n",
    "    to_vec += f\"Spec of the beer are: {abv=}, {ibu=}, {srm=}\"\n",
    "    return to_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94f66f7-1f4e-49d2-9819-2556a26f3073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_description = (\n",
    "    df_beers\n",
    "    .withColumn(\"beer_text\", F.coalesce(F.col(\"descript\"), F.lit(\"\")))\n",
    "    .withColumnRenamed(\"name\", \"beer_name\")\n",
    "    .join(\n",
    "        (\n",
    "            df_breweries\n",
    "            .select([\"id\", \"name\", \"descript\"])\n",
    "            .withColumn(\"brewer_text\", F.coalesce(F.col(\"descript\"), F.lit(\"\")))\n",
    "            .withColumnRenamed(\"name\", \"brewer_name\")\n",
    "        ), \n",
    "        on=df_beers.brewery_id == df_breweries.id\n",
    "    )\n",
    "    .drop(df_breweries[\"id\"])\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edd2d668-269b-4db5-8d49-15dc7947fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class JinaEmbedder:\n",
    "    \n",
    "    URL = 'https://api.jina.ai/v1/embeddings'\n",
    "    EMBEDDING_NAME = \"jina-embeddings-v2-base-en\"\n",
    "    bearer_token = 'Bearer jina_85ba1ab9e5ff4017b3d216ebb8734f27xzJ9WyoYBFwqks9lOaNLHryw_Yyz'\n",
    "\n",
    "    @staticmethod\n",
    "    def http_json_to_vec(http_json: dict):\n",
    "        return np.array(\n",
    "            [\n",
    "                sentence[\"embedding\"]\n",
    "                for sentence in http_json[\"data\"]\n",
    "            ]\n",
    "        )        \n",
    "\n",
    "    @classmethod\n",
    "    def embed(cls, str_to_vectorize: List[str] | str) -> np.ndarray:\n",
    "        if isinstance(str_to_vectorize, str):\n",
    "            str_to_vectorize = [str_to_vectorize]\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': cls.bearer_token\n",
    "        }\n",
    "        data = {\n",
    "            'model': cls.EMBEDDING_NAME,\n",
    "            'normalized': True,\n",
    "            'embedding_type': 'float',\n",
    "            'input': str_to_vectorize\n",
    "        }\n",
    "        \n",
    "        response = requests.post(cls.URL, headers=headers, json=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error code {response.status_code} on this call\")\n",
    "\n",
    "        return JinaEmbedder.http_json_to_vec(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "209a032b-8514-4e21-ada1-17cae2ceddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/13 12:24:36 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "df_vec = (\n",
    "    df_description\n",
    "    .withColumn(\"to_vec\", craft_to_txt_vectorize(\"beer_name\", \"brewer_name\", \"beer_text\", \"brewer_text\", \"abv\", \"ibu\", \"srm\"))\n",
    "    .repartition(32)\n",
    "    .select(\"id\", \"to_vec\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ddf76f1e-35b1-4304-816a-fa4f9c6825c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = F.udf(JinaEmbedder.embed, ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "74fb882a-b786-4550-9b09-92bbd7a99cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = (\n",
    "    df_vec.withColumn(\"embedding\", embed(\"to_vec\"))\n",
    "    .cache()\n",
    "    .select([\"id\", \"embedding\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f947f07-d53c-4f2d-b175-9c147e179ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3899</td>\n",
       "      <td>the beer Wipeout IPA from brewery Port Brewing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5377</td>\n",
       "      <td>the beer Hopfen Weisse from brewery Private We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>the beer Russian Imperial Stout from brewery I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5831</td>\n",
       "      <td>the beer IPA Series (Horizon) from brewery App...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4936</td>\n",
       "      <td>the beer Scratch #13 2008 from brewery Troegs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>5612</td>\n",
       "      <td>the beer Lake Placid Frostbite Ale from brewer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>198</td>\n",
       "      <td>the beer Old Guardian Barley Wine 2007 from br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>3744</td>\n",
       "      <td>the beer Champions Clubhouse Classic from brew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>3385</td>\n",
       "      <td>the beer Best Bitter from brewery Niagara Fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>1637</td>\n",
       "      <td>the beer Kristall Weissbier from brewery Bayer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             to_vec\n",
       "0     3899  the beer Wipeout IPA from brewery Port Brewing...\n",
       "1     5377  the beer Hopfen Weisse from brewery Private We...\n",
       "2     1004  the beer Russian Imperial Stout from brewery I...\n",
       "3     5831  the beer IPA Series (Horizon) from brewery App...\n",
       "4     4936  the beer Scratch #13 2008 from brewery Troegs ...\n",
       "...    ...                                                ...\n",
       "5901  5612  the beer Lake Placid Frostbite Ale from brewer...\n",
       "5902   198  the beer Old Guardian Barley Wine 2007 from br...\n",
       "5903  3744  the beer Champions Clubhouse Classic from brew...\n",
       "5904  3385  the beer Best Bitter from brewery Niagara Fall...\n",
       "5905  1637  the beer Kristall Weissbier from brewery Bayer...\n",
       "\n",
       "[5906 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_vec.toPandas()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cb50fd3-928e-431d-be81-89bab5a75fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055ae11-d63f-459b-8bba-a541df6ee5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
