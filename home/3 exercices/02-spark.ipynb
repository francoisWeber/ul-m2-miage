{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4184713b-3d12-4e5b-abc8-d9b85922f01e",
   "metadata": {},
   "source": [
    "# Intro to Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca111e-9330-43db-8b1a-d13712013a2f",
   "metadata": {},
   "source": [
    "**Disclaimer:** TP plus compliqué !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806be423-194a-4a2e-8403-2435353e5c3e",
   "metadata": {},
   "source": [
    "**Spark** est un système de calcul hautement parallélisé :\n",
    "- au niveau du stockage : la data est fragmentée, dupliquée, répartie sur un nombre quelconque de disques/servers\n",
    "- au niveau du calcul : les calculs s'exécutent en parallèle sur plusieurs machines, chacune sur sa portion de data\n",
    "\n",
    "Spark en tant que tel est un framework qui a des implémentation dans plusieurs langages :\n",
    "- Python via PySpark (ce qe nous utiliserons)\n",
    "- Scala\n",
    "- R\n",
    "- Java\n",
    "\n",
    "## Quelques informations en vrac sur Spark\n",
    "### Hardware\n",
    "- Spark peut s'installer sur un grand nombre de machines situées dans un même réseau. Elles pourront ensuite se reconnaître et collaborer. 1 unité de calcul = 1 noeud.\n",
    "- Spark fonctionne sur le mode master/worker : un noeud est désigné `master` et jouera le rôle de chef d'orchestre pour que les autres noeuds `workers` exécutent les tâches dans le bon ordre\n",
    "- Les noeuds Spark communiquent énormément entre eux pour s'échanger des informations et surtout des données\n",
    "\n",
    "### Software\n",
    "- Un code Spark / PySpark doit utiliser les primitives Spark pour que tout s'exécute selon la logique Spark\n",
    "- Le code pyspark est transmis au noeud `master` qui le lit et prépare l'orchestration des calculs selon les `workers` qu'il a à disposition. Seuls les `workers` manipuleront la donnée (sauf exception)\n",
    "- Spark est *lazy* : `master` ne lance réellement aucun calcul tant qu'il n'a pas lu d'opération impliquant l'affichage ou l'écriture des résultats\n",
    "- Corrolaire du *lazy* : sans précaution, Spark peut répéter plusieurs fois les mêmes calculs ... Exemple avec 2 chaînes de transformation data `A -> B -> C -> D` suivi de `A -> B -> E`. Les étapes intermédiaires `A -> B` sont identiques mais pour calculer `D` et `E`, Spark risque de les exécuter 2 fois. Apprendre à manipuler les méthodes [cache](https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.cache.html?highlight=cache) !\n",
    "\n",
    "### Framework\n",
    "- Spark se base sur des `DataFrame` très proches en terme d'utilisation des `pandas.DataFrame` donc pas de panique :)\n",
    "- Spark gère tout ce que sait gérer SQL mais part de fichiers plats (ici CSV) : join, select, etc ...\n",
    "- PySpark permet de gérer tout ces concepts avec la facilité d'accès du Python\n",
    "- PySpark est TRÈS typé et a besoin de connaître les types de chaque colonne manipulées\n",
    "- Spark est TRÈS flexible en terme de configuration et d'exécution et cela peut sembler déroutant pour des exemples simples\n",
    "\n",
    "### Organisation du calcul\n",
    "En informatique, à chaque architecture ses optimisations :\n",
    "- en local sur 1 CPU, un calcul possède peu d'optimisation : simple et linéaire, possiblement async\n",
    "- en local sur multi CPU, un calcul doit être prévu pour paralléliser les exécutions sur plusieurs coeurs physiques\n",
    "- en local sur mono/multi GPU, un calcul doit être hautement parallélisable, découpable en tranche de data qui tiennent en GPU-RAM\n",
    "- en multi machine multi GPU, idem que plus haut avec bande passante importante entre machine pour échange d'information\n",
    "\n",
    "... Spark gère le multi machine, multi CPU, multi RAM, multi disque : calculs hautement parallélisés grâce à la magie de Spark, data échangées au mieux entre machine (possiblement avec l'aide humaine).\n",
    "__Spark est toujours prêt à gérer un contexte d'exécution très complexe__ => il faut s'attendre à beaucoup d'overhead sur des cas simples\n",
    "\n",
    "**Les opérations s'exécutent sur des workers séparés, en parallèle**, il faut donc parfois faire \"un peu attention\" à la façon dont on demande à Spark de *partitionner* sa data.\n",
    "\n",
    "## À retenir\n",
    "\n",
    "1. Spark et son implémentation PySpark sont très puissant car gèrent un parallélisme quasi infini et réglable à 100%\n",
    "2. PySpark a un coût d'entrée pour se couler dans le moule Spark mais permet de réaliser des opérations très complexes avec la simplicité du Python\n",
    "3. Votre notebook n'exécutera n'a pas accès à la data manipulée et n'effectuera aucun calculs ; il les transmettra au Spark Master qui les répartira entre ses workers qui ont accès à la data\n",
    "\n",
    "## Exemple de code Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8621c-611b-4c65-ba9c-521bde327143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e72be-8c66-465d-bdbd-13a50d34c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    url = \"http://embedder:8000/embed\"\n",
    "    payload = {\"text\": text}\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318386f-71ef-44ec-aaf9-160ecd6ff0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36207d6-6c1d-4e0a-a9ad-5748352ab552",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_ID = \"François\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea6256-c381-4264-99b8-8987b21e8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PySpark session\n",
    "assert MY_ID is not None, \"provide your id first!\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(MY_ID) \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "# /!\\ Tout se fera à partir de cet object magique `spark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fccced-12e3-4a36-a9d4-7884eab014ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Catherine\", 3)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Value\"])\n",
    "\n",
    "# Show the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328d481-2517-43d6-af84-935714cc9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, FloatType, ArrayType, StructField, StructType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365084ed-4817-426d-919d-13f827892be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers = spark.read.csv(\"/datasets/csv/beers.csv\", header=True)\n",
    "df_beers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194190e-50b3-4e2d-a44c-24ded27a9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define a specific funtion to map beer names\n",
    "@F.udf(returnType=StringType())\n",
    "def revert_cap_name(name: str):\n",
    "    return name[::-1].upper()\n",
    "\n",
    "\n",
    "df_beers.repartition(12).withColumn(\"reverse_capitalized\", revert_cap_name(F.col(\"name\"))).select(\"name\", \"reverse_capitalized\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25580a-421d-41c6-bdb8-6ebe81a4b39b",
   "metadata": {},
   "source": [
    "## Observations\n",
    "Que remarque-t-on tout de suite ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672354a-2827-42fc-a265-fcedd0e8affc",
   "metadata": {},
   "source": [
    "# Uses cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19828ca-a8ba-4727-8258-b748ce8afb83",
   "metadata": {},
   "source": [
    "# UC-1 : description data\n",
    "\n",
    "- Q1: Combien y a-t-il de bières dans la DB ?\n",
    "- Q2: Top10 brasseries les plus représentées avec le nombre de bière par brasserie ?\n",
    "- Q3: Top10 des bières les plus fortes (ABV) en France ?\n",
    "- Q4: Par pays, nombre de brasseries qui proposent des bières de type `Porter` et ABV moyen de celles-ci ?\n",
    "- Q5: Mediane du nombre de bière par pays ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d29ccd-27f6-4235-a3c1-996c14480f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "df_beers = spark.read.csv(\"/datasets/csv/beers.csv\", header=True)\n",
    "df_beers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccbce5-7f70-4624-acb3-86a8768bb6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 \n",
    "df_breweries = spark.read.csv(\"/datasets/csv/breweries.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20115ddc-712b-4eb3-991c-9ed13871d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers.filter(F.col(\"name\").ilike(\"Ho%\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f0b36-c7a3-41e6-ac14-d7368a77e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_beer_brew = (\n",
    "    df_breweries.join(df_beers, on=df_beers.brewery_id == df_breweries.id)\n",
    "    .select(df_breweries.name)\n",
    "    .groupby(F.col(\"name\"))\n",
    "    .count()\n",
    "    .sort(\"count\", ascending=False)\n",
    "    .limit(10)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15cacb-d45b-43d4-a85a-c05c10a3d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers.filter(F.col(\"name\").ilike(\"Belz%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1be919-2311-4bb6-adea-6b6607777b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 top 10 bières FR les plus fortes\n",
    "df = (\n",
    "    df_beers.join(df_breweries, on=df_beers.brewery_id == df_breweries.id)\n",
    "    .filter(F.col(\"country\") == F.lit(\"France\"))\n",
    "    .select([df_beers.name, df_beers.abv.cast(FloatType())])\n",
    "    .sort(\"abv\", ascending=False)\n",
    "    .limit(10)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef86ac-6ac2-42ba-895e-e8f5b101624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_style = spark.read.csv(\"/datasets/csv/styles.csv\", header=True)\n",
    "df_style.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c427f2-1372-4e41-9943-e1803d219f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_style\n",
    "    .select(df_style.id.alias(\"style_id\"), \"style_name\")\n",
    "    .filter(F.col(\"style_name\").ilike(\"%Porter%\"))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9135e-9d4c-4a2d-81ea-dbaa7c6331fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=FloatType())\n",
    "def safe_cast_to_float(str_float: str):\n",
    "    return float(str_float)\n",
    "\n",
    "df_beers_brewers = (\n",
    "    df_beers\n",
    "    .join(df_breweries.withColumnRenamed(\"name\", \"brewer_name\"), on=df_beers.brewery_id == df_breweries.id)\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103e61c-7965-42f3-bf38-d78d7b6874d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Q4\")\n",
    "df_style = spark.read.csv(\"/datasets/csv/styles.csv\", header=True)\n",
    "target_style_id = df_style.filter(F.lower(F.col(\"style_name\")) == \"porter\").select(F.col(\"id\").alias(\"style_id\"))\n",
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .join(target_style_id, how=\"inner\", on=\"style_id\")\n",
    "    .withColumn(\"abv_float\", safe_cast_to_float(F.col(\"abv\")))\n",
    "    .select([\"name\", \"brewer_name\", \"abv_float\", \"country\"])\n",
    "    .groupby(\"country\")\n",
    "    .agg(F.avg(\"abv_float\").alias(\"avg_abv\"), F.countDistinct(\"brewer_name\").alias(\"n_brewer_having_porter\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb54fa-6c56-4201-8918-125fe4eca640",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Q5\")\n",
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .groupby(\"country\")\n",
    "    .count()\n",
    "    .agg(F.median(\"count\"))\n",
    ")\n",
    "print(\"Q5:\", dd.first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82d2e7-274a-49e8-bb1f-5d491bec2609",
   "metadata": {},
   "source": [
    "# UC-2 : préparer un dataset de ranking \n",
    "Tout moteur de recherche/search-engine - **SE** - nécessite de la configuration ... beaucoup de configuration. Une des configuration très orientée \"data\" est le calcul que l'index doit opérer pour scorer chaque réponse possible face à une requête. L'apprentissage statistique de ce score s'appelle *Learning to Rank*  - **LTR** - et nécessite des connaissances poussées en machine learning. \n",
    "\n",
    "Cette tâche LTR se base sur les *feedbacks implicites* des utilisateurs face au moteur de recherche. Commençons par un exemple. Quand vous cherchez un objet sur LeBonCoin, vous laissez plusieurs informations *implicites* sur votre perception des résultats proposés : les item sur lesquels vous avez cliqués bien sûr mais également ceux que vous avez probablement *vu* sans cliquer dessus ... Ces \"vues sans clics\" sont une précieuse information implicite sur les jugement que vous avez porté aux résultats proposés. Pour ce TP nous nous limiterons à ce concept de \"vu x click\" mais il est possible d'aller plus loin (dwell-time, hierarchisation des interactions explicites, ...). \n",
    "\n",
    "On appelle *Search Engine Results Page* - **SERP** - la liste des résultats classés par un SE. Un document qui figure dans les résulats d'une recherche a donc une position (son rang) au sein de la **SERP**.\n",
    "\n",
    "Exemple, où :\n",
    "- `query` est la recherche réalisée par un user et qui a débouché sur une SERP\n",
    "- `clicked_id` : l'id de la bière cliquée par le user\n",
    "- `user_id` l'id de l'utilisateur (simplifions en disant que c'est même l'id d'une recherche) : permet de retrouver tous les résultats proposés dans **une** recherche\n",
    "- `id_in_serp` : l'id d'une bière figurant dans la SERP\n",
    "- `pos_in_serp` : la position/le rang de la bière `id_in_serp` dans la SERP issue de la recherche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153f482-d334-4f46-8134-d25dfe0643a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref = spark.read.csv(\"/datasets/beers_feedback.csv\", header=True, inferSchema=True)\n",
    "df_pref.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28882f0-de9a-4fbc-97c5-a37864103477",
   "metadata": {},
   "source": [
    "Un travail préliminaire au LTR est la constitution d'un dataset qui permet d'aggréger ces feedbacks laissés par tous les utilisateurs ayant réalisé la même query. Chacun a vu et cliqué selon ses propres impressions de pertinence et il convient de \"moyenner\" tout cela pour obtenir des appréciations globales. L'objectif d'un tel dataset est de pouvoir lister des exemples de triplets `(query, document, note)` qui permet de savoir que face à une *query* `milky stout low bitterness`, un *document* `Super bitter beer brewed with organic roasted barley and chocolate` aura une pertinence de *1/4* (arbitraire). \n",
    "\n",
    "Implémenter le modèle d'agrégation de feedback \"cascade model\" [1] (pour la culture, **inutile d'avoir lu l'article** pour le TD) qui propose une approche pragmatique pour obtenir ces données. La méthode est la suivante :\n",
    "- pour chaque recherche utilisateur:\n",
    "    - étudier la position de l'id cliqué dans la SERP - soit `clicked_pos_in_serp` cette information\n",
    "    - Considérer que tout doc situés \"au-dessus dans la SERP\" (càd quand `pos_in_serp <= clicked_pos_in_serp`) avait été vu par l'utilisateur\n",
    "    - Récapituler tous ces documents \"vus et cliqués\" et \"vus mais pas cliqués\"\n",
    "- Pour chaque recherche et bière cliquée (`clicked_id`), calculer la \"probabilité de clic sachant qu'elle a été vue\", càd le nombre de fois qu'elle a été cliquée divisé par le nombre de fois où elle a été vue\n",
    "\n",
    "\n",
    "[1] https://dl.acm.org/doi/abs/10.1145/1341531.1341545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3945da0-7065-4872-a82e-54df5b84f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output schema : https://stackoverflow.com/a/54771215/10716281\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "mapping = {\n",
    "    \"float64\": DoubleType,\n",
    "    \"object\":StringType,\n",
    "    \"int64\":IntegerType,\n",
    "    \"int32\":IntegerType,\n",
    "    \"bool\": BooleanType,\n",
    "} # Incomplete - extend with your types.\n",
    "\n",
    "def createUDFSchemaFromPandas(dfp):\n",
    "  column_types  = [StructField(key, mapping[str(dfp.dtypes[key])]()) for key in dfp.columns]\n",
    "  schema = StructType(column_types)\n",
    "  return schema\n",
    "\n",
    "def compute_cascade_model_per_user_query(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pos_of_clicked_id = df[df[\"id_in_serp\"] == df[\"clicked_id\"]].iloc[0][\"pos_in_serp\"]\n",
    "    df[\"seen\"] = (df[\"pos_in_serp\"] <= pos_of_clicked_id).astype(int)\n",
    "    df[\"clicked\"] = np.where(df[\"pos_in_serp\"] == pos_of_clicked_id, 1, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbf55e-8648-4f59-871d-19cc065794b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = compute_cascade_model_per_user_query(df_pref.limit(3).toPandas())\n",
    "schema = createUDFSchemaFromPandas(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc2e9b-3d4c-4b02-b93f-d2401b1b34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    df_pref\n",
    "    .repartition(12, \"query\", \"user_id\")\n",
    "    .groupby([\"query\", \"user_id\"])\n",
    "    .applyInPandas(compute_cascade_model_per_user_query, schema)\n",
    "    .filter(F.col(\"seen\") == F.lit(1))\n",
    "    .groupby([\"query\", \"id_in_serp\"])\n",
    "    .agg(F.sum(\"seen\").alias(\"n_seen\"), F.sum(\"clicked\").alias(\"n_clicked\"))\n",
    "    .withColumn(\"clic_proba\", F.col(\"n_clicked\") / F.col(\"n_seen\"))\n",
    "    .select([\"query\", \"id_in_serp\", \"clic_proba\"])\n",
    "    .sort([\"query\", \"id_in_serp\"], ascending=False)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc322fe-1b84-4e03-bd19-94b990936806",
   "metadata": {},
   "source": [
    "# UC-3.0 Génération de keywords pour chaque bière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba5574-b2b3-41c2-af30-42fe45bd2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_beers.filter(F.col(\"descript\").isNotNull()).withColumn(\"descript_lower\", F.lower(\"descript\")).select(\"id\", \"descript_lower\")\n",
    "corpus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7e1ea-c388-478f-a9de-fe6604952f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_count_per_beer_id = (\n",
    "    corpus\n",
    "    .withColumn(\"words\", F.explode(F.split(F.col(\"descript_lower\"), \" \")))\n",
    "    .select(\"id\", \"words\")\n",
    "    .groupby(\"id\", \"words\")\n",
    "    .count().withColumnRenamed(\"count\", \"term_freq_in_doc\")\n",
    ").cache()\n",
    "df_words_count_per_beer_id = (\n",
    "    df_words_count_per_beer_id\n",
    "    .groupby(\"words\")\n",
    "    .sum().withColumnRenamed(\"sum(term_freq_in_doc)\", \"term_freq_in_corpus\")\n",
    "    .join(df_words_count_per_beer_id, on=\"words\")\n",
    "    .filter(F.col(\"term_freq_in_corpus\") >= F.lit(2))\n",
    "    .withColumn(\"tfidf\", F.col(\"term_freq_in_doc\") / F.col(\"term_freq_in_corpus\"))\n",
    ")\n",
    "df_words_count_per_beer_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72397466-eb15-4236-96a1-80ae90513230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_count_per_beer_id.sort(\"tfidf\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db1c17-9959-45a8-a53c-64697067b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88616d-e1cb-4ee7-be7d-b3f10911b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"id\").orderBy(F.col(\"tfidf\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb676b0-f2d4-4842-a379-b71f0d76dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_words_count_per_beer_id\n",
    "    .withColumn(\"ranked\", F.row_number().over(window_spec))\n",
    "    .filter(F.col(\"ranked\") <= F.lit(3))\n",
    "    .groupby(\"id\")\n",
    "    .agg(F.collect_list(\"words\"))\n",
    "    .withColumnRenamed(\"collect_list(words)\", \"keywords\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd69723-3c9d-4bfe-a564-61c163e33f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fb62b-e0de-4828-bf80-41cd8b24a1cc",
   "metadata": {},
   "source": [
    "## UC-3.1 langdetect over descripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb6d83-4f06-4fbc-976b-6c1bc4eee1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@F.udf(returnType=StringType())\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return langdetect.detect(text)\n",
    "    except langdetect.LangDetectException:\n",
    "        return \"ukn\"\n",
    "\n",
    "spark_langdetect = F.udf(detect_lang, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2508d3b-e7ef-42db-8321-0b0d67e50de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_beers\n",
    "    .filter(F.col(\"descript\").isNotNull())\n",
    "    .select(\"id\", \"descript\")\n",
    "    .withColumn(\"lang\", spark_langdetect(F.col(\"descript\")))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880899d1-fd71-41a6-b467-b7ce8224bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.descript.str.len() >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7d7d-247a-4086-9690-e85e6ef5c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(text):\n",
    "    try:\n",
    "        return langdetect.detect(text)\n",
    "    except langdetect.LangDetectException:\n",
    "        return \"ukn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f313e1-c0d5-4f26-ba9b-f91b813273bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lang\"] = df.descript.apply(detect_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab99678-1b76-4c31-8e1b-5b74e1fce647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"lang\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1646b-d653-496a-be37-0d425c1abadd",
   "metadata": {},
   "source": [
    "# UC-3 : récupérer les docs qui parlent d'un mot\n",
    "\n",
    "Peut-on utiliser SQL pour réaliser un mini moteur de recherche ? Pour différentes requêtes (`query` en anglais) textuelles très simples à base de mot-clef, retrouver les bières qui semblent répondre à la demande. Exemples :\n",
    "- trouver les bières ou les brasseries qui parlent de bières \"fine\"\n",
    "- idem pour \"juicy\"\n",
    "- idem pour \"genuine\"\n",
    "- idem pour les bières mâturées dans des \"oak cask\" (fûts en chêne) -> combien y en a-t-il ? $N_1$\n",
    "   - idem pour les bières qui évoquent uniquement \"cask\" -> combien y en a-t-il ? $N_{1,1}$\n",
    "   - idem pour celles ne parlant que de \"oak\" -> combien y en a-t-il ? $N_{1,2}$\n",
    "- idem pour les bières qui évoquent \"oak\" et \"cask\" -> combien y en a-t-il ? $N_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fd4dd-8135-4f27-a0cb-2c8baeb1df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d942b-9c0d-46b5-afa1-b46dfcb4393f",
   "metadata": {},
   "source": [
    "# UC-4 : vectorisation des description des bières\n",
    "Préparer le recours à un service de vectorisation qui permettra de convertir la connaissance sur une bière en un vecteur numérique. Ce vecteur permet de sythétiser mathématiquement l'information disponible sur une bière et sa brasserie et pourra être réutilisé plus tard dans un moteur de recherche.\n",
    "à faire :\n",
    "- Préparer une description la plus complète possible pour chaque bière\n",
    "- envoyer ces descriptions une à une via un appel HTTP sur Jina (voir instruction plus bas)\n",
    "\n",
    "**Découpez le travail** : chacun travaillera sur un sous-ensemble de bières selon l'`id` de chaque bière `beers.id`. \n",
    "Vous êtes 12, je propose donc la répartition suivante :\n",
    "- ADAM.LUCAS --> s'occuper des `beers.id` égaux à 0 modulo 12\n",
    "- ALIEINIK.OLHA --> s'occuper des `beers.id` égaux à 1 modulo 12\n",
    "- ARNOUT.FABRICE --> s'occuper des `beers.id` égaux à 2 modulo 12\n",
    "- BEDIER.DORIANE --> s'occuper des `beers.id` égaux à 3 modulo 12\n",
    "- CASTRO.MOUCHERON --> s'occuper des `beers.id` égaux à 4 modulo 12\n",
    "- COLIN.KEVIN --> s'occuper des `beers.id` égaux à 5 modulo 12\n",
    "- FRASELLE.NADEGE --> s'occuper des `beers.id` égaux à 6 modulo 12\n",
    "- KUKSA.OLEKSANDRA --> s'occuper des `beers.id` égaux à 7 modulo 12\n",
    "- LOPES.VAZ.ALEXIS --> s'occuper des `beers.id` égaux à 8 modulo 12\n",
    "- REITER.ROMAIN --> s'occuper des `beers.id` égaux à 9 modulo 12\n",
    "- RICHIER.MARCUS --> s'occuper des `beers.id` égaux à 10 modulo 12\n",
    "- VINOT.MATHIEU --> s'occuper des `beers.id` égaux à 11 modulo 12\n",
    "\n",
    "## Service de vectorisation Jina\n",
    "Nous allons faire appel à un service de vectorisation externe [https://jina.ai](https://jina.ai) qui propose gratuitement 1M token de vectorisation. \n",
    "Quand vous voudrez vectoriser un texte, suivez la doc de [https://jina.ai/embeddings/](https://jina.ai/embeddings/). \n",
    "\n",
    "Nous utiliserons **TOUS le MÊME modèle d'embedding** : `jina-embeddings-v2-base-en` ! Faites donc attention à appeler le bon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1cfee-f1dc-4842-bd80-c30f4d1c57b3",
   "metadata": {},
   "source": [
    "Essayons de construire d'avoir tous le même schéma de texte à vectoriser :\n",
    "`the beer BEER_NAME from brewery BREWERY_NAME (BREWERY_DESCRIPTION) is defined as BEER_DESCRIPTION. Spec of the beer are: ABV=ABV_VALUE, IBU=IBU_VALUE, SRM=SRM_VALUE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ee4db-2551-41b8-aa2c-e62e00f29f6d",
   "metadata": {},
   "source": [
    "#### Instructions pour appeler le service Jina\n",
    "En plus de la doc sur leur site, voici un snippet de code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b09324-7f15-4e5f-a855-79973a7f9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    url = \"http://embedder:8000/embed\"\n",
    "    payload = {\"text\": text}\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    try:\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        return response.json()[\"vector\"]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "spark_get_embedding = F.udf(get_embedding, returnType=ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66632c-0c75-461d-83a3-503d36ab31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(    df_beers\n",
    "    .repartition(32)\n",
    "    .filter(F.col(\"descript\").isNotNull())\n",
    "    .select(\"id\", \"descript\")\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3b9af-b070-4c55-9751-1756b8e8a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = (\n",
    "    df_beers\n",
    "    .repartition(32)\n",
    "    .filter(F.col(\"descript\").isNotNull())\n",
    "    .select(\"id\", \"descript\")\n",
    "    .withColumn(\"lang\", spark_get_embedding(F.col(\"descript\")))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e8ad3-5ede-4ae0-95ae-157d31783de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d106a-bcd8-4d46-9200-c7d6bd88797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee22f37-b07e-4f63-935e-f153e680f089",
   "metadata": {},
   "source": [
    "# UC-5 : answer question in corpa\n",
    "\n",
    "**Question difficile en Spark**\n",
    "\n",
    "**Grandes lignes :** trouvons les documents qui répondent à une question. Exemple : à partir de la description vectorisée à UC-4 pour chaque bière, comment trouver les bières qui répondent à une description plus complète ? Exemple:\n",
    "- \"very bitter beer with smoky taste\"\n",
    "- \"fruity sour - balanced sourness\"\n",
    "- \"weird beer\"\n",
    "\n",
    "Voir la doc [Spark ML lib - feature extraction](https://spark.apache.org/docs/latest/api/python/reference/pyspark.mllib.html#feature) pour trouver des idées (TF-IDF, Word2Vec), ou utiliser le résultats de vos vectorisation de UC-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3257601-6abd-403f-9a13-3f59e2f1973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"very bitter beer with smoky taste\", \"fruity sour - balanced sourness\", \"weird beer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e84e9-7e74-4fed-8e04-707fb66542de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
