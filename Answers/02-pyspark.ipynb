{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Initialize PySpark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JupyterHub PySpark Example\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "# /!\\ Tout se fera à partir de cet object magique `spark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beers = spark.read.csv(\"/datasets/csv/beers.csv\", header=True)\n",
    "df_breweries = spark.read.csv(\"/datasets/csv/breweries.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=FloatType())\n",
    "def safe_cast_to_float(str_float: str):\n",
    "    return float(str_float)\n",
    "\n",
    "df_beers_brewers = (\n",
    "    df_beers\n",
    "    .join(df_breweries.withColumnRenamed(\"name\", \"brewer_name\"), on=df_beers.brewery_id == df_breweries.id)\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "n_beers = df_beers.count()\n",
    "print(f\"Q1: {n_beers} dans la DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Q2\")\n",
    "dd = (df_beers\n",
    "      .join(df_breweries, on=df_beers.brewery_id == df_breweries.id)\n",
    "      .groupby(\"country\")\n",
    "      .count()\n",
    "      .sort(F.col(\"count\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Q3\n",
    "\n",
    "@F.udf(returnType=FloatType())\n",
    "def safe_cast_to_float(str_float: str):\n",
    "    return float(str_float)\n",
    "\n",
    "df_beers_brewers = (\n",
    "    df_beers\n",
    "    .join(df_breweries.withColumnRenamed(\"name\", \"brewer_name\"), on=df_beers.brewery_id == df_breweries.id)\n",
    ").cache()\n",
    "\n",
    "print(\"Q3\")\n",
    "dd = (df_beers_brewers\n",
    "      .filter(F.col(\"country\") == F.lit(\"France\"))\n",
    "      .withColumn(\"abv_float\", safe_cast_to_float(F.col(\"abv\")))\n",
    "      .sort(F.col(\"abv_float\").desc())\n",
    "      .select([\"name\", \"abv_float\", \"country\"])\n",
    "      .limit(10)\n",
    ")\n",
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Q4\")\n",
    "df_style = spark.read.csv(\"/datasets/csv/styles.csv\", header=True)\n",
    "target_style_id = df_style.filter(F.lower(F.col(\"style_name\")) == \"porter\").select(F.col(\"id\").alias(\"style_id\"))\n",
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .join(target_style_id, how=\"inner\", on=\"style_id\")\n",
    "    .withColumn(\"abv_float\", safe_cast_to_float(F.col(\"abv\")))\n",
    "    .select([\"name\", \"brewer_name\", \"abv_float\", \"country\"])\n",
    "    .groupby(\"country\")\n",
    "    .agg(F.avg(\"abv_float\").alias(\"avg_abv\"), F.countDistinct(\"brewer_name\").alias(\"n_brewer_having_porter\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Q5\")\n",
    "dd = (\n",
    "    df_beers_brewers\n",
    "    .groupby(\"country\")\n",
    "    .count()\n",
    "    .agg(F.median(\"count\"))\n",
    ")\n",
    "print(\"Q5:\", dd.first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC-2\n",
    "Exo difficile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output schema : https://stackoverflow.com/a/54771215/10716281\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "mapping = {\n",
    "    \"float64\": DoubleType,\n",
    "    \"object\":StringType,\n",
    "    \"int64\":IntegerType,\n",
    "    \"int32\":IntegerType,\n",
    "    \"bool\": BooleanType,\n",
    "} # Incomplete - extend with your types.\n",
    "\n",
    "def createUDFSchemaFromPandas(dfp):\n",
    "  column_types  = [StructField(key, mapping[str(dfp.dtypes[key])]()) for key in dfp.columns]\n",
    "  schema = StructType(column_types)\n",
    "  return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cascade_model_per_user_query(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pos_of_clicked_id = df[df[\"id_in_serp\"] == df[\"clicked_id\"]].iloc[0][\"pos_in_serp\"]\n",
    "    df[\"seen\"] = (df[\"pos_in_serp\"] <= pos_of_clicked_id).astype(int)\n",
    "    df[\"clicked\"] = np.where(df[\"pos_in_serp\"] == pos_of_clicked_id, 1, 0)\n",
    "    return df\n",
    "\n",
    "df_processed = compute_cascade_model_per_user_query(df_pref.limit(3).toPandas())\n",
    "schema = createUDFSchemaFromPandas(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_pref\n",
    "    .repartition(16, \"query\", \"user_id\")\n",
    "    .groupby([\"query\", \"user_id\"])\n",
    "    .applyInPandas(compute_cascade_model_per_user_query, schema)\n",
    "    .filter(F.col(\"seen\") == F.lit(1))\n",
    "    .groupby([\"query\", \"id_in_serp\"])\n",
    "    .agg(F.sum(\"seen\").alias(\"n_seen\"), F.sum(\"clicked\").alias(\"n_clicked\"))\n",
    "    .withColumn(\"clic_proba\", F.col(\"n_clicked\") / F.col(\"n_seen\"))\n",
    "    .select([\"query\", \"id_in_serp\", \"clic_proba\"])\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC-3 search from a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation :** On ne pourra pas aller bien loin en terme de souplesse dans la requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_description = (\n",
    "    df_beers\n",
    "    .select([\"id\", \"name\", \"descript\", \"brewery_id\"])\n",
    "    .withColumn(\"beer_text\", F.coalesce(F.col(\"descript\"), F.lit(\"\")))\n",
    "    .withColumnRenamed(\"name\", \"beer_name\")\n",
    "    .join(\n",
    "        (\n",
    "            df_breweries\n",
    "            .select([\"id\", \"name\", \"descript\"])\n",
    "            .withColumn(\"brewer_text\", F.coalesce(F.col(\"descript\"), F.lit(\"\")))\n",
    "            .withColumnRenamed(\"name\", \"brewer_name\")\n",
    "        ), \n",
    "        on=df_beers.brewery_id == df_breweries.id\n",
    "    )\n",
    "    .withColumn(\"text\", F.concat(F.col(\"beer_text\"), F.lit(\". \"), F.col(\"brewer_text\")))\n",
    "    .select([\"beer_name\", \"brewer_name\", \"text\"])\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"stout\"\n",
    "df_description.filter(F.col(\"text\").contains(query)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC-4 vectorize items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH data AS (\n",
    "    SELECT \n",
    "        beers.id, beers.name, beers.abv, beers.ibu, beers.srm, beers.descript as beer_descr,\n",
    "        brew.descript as brewer_descript, brew.name as brewery,\n",
    "        styles.style_name\n",
    "    FROM beers\n",
    "    LEFT JOIN breweries as brew on brew.id = beers.brewery_id\n",
    "    LEFT JOIN styles on styles.id = beers.style_id\n",
    "), descriptions AS (\n",
    "    SELECT \n",
    "        id,\n",
    "        CONCAT('the beer ', name, ' from brewery ', brewery, ' (', brewer_descript, ') crafts the beer ', name, ' defined as ', beer_descr, '. Spec of the beer are: ABV=', abv, ', IBU=', ibu, ', SRM=', srm) as to_vectorize\n",
    "    FROM data\n",
    ")\n",
    "SELECT \n",
    "    id, to_vectorize\n",
    "FROM descriptions\n",
    "WHERE True\n",
    "    AND id % 12 = 3\n",
    ";\"\"\"\n",
    "df = pd.read_sql_query(q, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class JinaEmbedder:\n",
    "    \n",
    "    URL = 'https://api.jina.ai/v1/embeddings'\n",
    "    EMBEDDING_NAME = \"jina-embeddings-v2-base-en\"\n",
    "    bearer_token = 'Bearer jina_85ba1ab9e5ff4017b3d216ebb8734f27xzJ9WyoYBFwqks9lOaNLHryw_Yyz'\n",
    "\n",
    "    @staticmethod\n",
    "    def http_json_to_vec(http_json: dict):\n",
    "        return np.array(\n",
    "            [\n",
    "                sentence[\"embedding\"]\n",
    "                for sentence in http_json[\"data\"]\n",
    "            ]\n",
    "        )        \n",
    "\n",
    "    @classmethod\n",
    "    def embed(cls, str_to_vectorize: List[str] | str) -> dict:\n",
    "        if isinstance(str_to_vectorize, str):\n",
    "            str_to_vectorize = [str_to_vectorize]\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': cls.bearer_token\n",
    "        }\n",
    "        data = {\n",
    "            'model': cls.EMBEDDING_NAME,\n",
    "            'normalized': True,\n",
    "            'embedding_type': 'float',\n",
    "            'input': str_to_vectorize\n",
    "        }\n",
    "        \n",
    "        response = requests.post(cls.URL, headers=headers, json=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error code {response.status_code} on this call\")\n",
    "\n",
    "        return JinaEmbedder.http_json_to_vec(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embeddings = JinaEmbedder.embed(df.iloc[:, 1].to_list())\n",
    "np.savez(\"./embedding-jina-id-3.npz\", my_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC-5 : answer question in corpa\n",
    "Pas vraiment de possibilité native en SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
