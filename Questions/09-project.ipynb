{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif du projet\n",
    "Le but du projet est de réaliser une petite architecture qui exploite avantageusement 2 des technos vues en TP - rappel:\n",
    "- DB SQL\n",
    "- Cache Redis\n",
    "- calculs sur Spark\n",
    "- index Vespa\n",
    "- vector DB QDrant \n",
    "Ajoutons à cela des services externes :\n",
    "- embedding à la demande via Jina.ai\n",
    "- LLM via ChatGPT, Mistral ou autres API (ne *pas* **hésiter** à recourir à ces nouveaux outils)\n",
    "\n",
    "## Modalités\n",
    "Par groupe de 2 ou 3, trouver un sujet précis, les data associées (un sample suffira pour illustrer le projet) et réaliser un code minimaliste qui répond au problème en exploitant les outils mis à disposition sur le cluster.\n",
    "\n",
    "Livrables : le code et une soutenance pour présenter le projet et expliquer les choix techniques. On prendra soin d'expliquer précisément le use-case choisi, les data, les contraintes (même théoriques), les détails technique de l'archi proposée pour y répondre. Tout choix technique devra être motivé théoriquement et pratiquement.\n",
    "Une petite démo fonctionnelle est attendue sur un petit dataset.\n",
    "\n",
    "Note : une pour chaque partie du livrable.\n",
    "\n",
    "## Exemples de sujets :\n",
    "\n",
    "Hint: un cache peut toujours servir par-ci, par-là :p \n",
    "\n",
    "### RAG, aka l'archi hype \n",
    "Le [Retrieval Augmented Generation](https://www.wikiwand.com/en/articles/Retrieval-augmented_generation), aka RAG, est une architecture très hyper pour questionner des documents via des LLM qui s'appuient sur des sources. L'architecture implique (au moins) \n",
    "- un index qui stocke les documents et se tient prêt à rendre les documents plus pertinents face à une query\n",
    "- un feeder qui parcourt les données stockées à plat, les nettoie, les découpe en tronçons pertinents (exemple: en pages / parties / chapitres) et les envoie sur l'index\n",
    "- un LLM qui lit la question posée, les documents rendus par l'index et synthétise une réponse claire\n",
    "\n",
    "Cas d'usage typique : une entreprise a énormément de documentation interne (contrats, paye, données techniques, etc) mais il est toujours difficile d'y accéder et de s'y retrouver. \n",
    "\n",
    "Data : n'importe quelle donnée qui contient des information qu'un utilisateur voudrait trouver ... la doc d'une lib (pour peu qu'elle soit bien fournie), un livre open-source, wikipedia, vos cours, vos notes persos ... \n",
    "\n",
    "### Analyse Common crawl\n",
    "\n",
    "Karen Fort propose un sujet autour du projet [Common Crawl](https://commoncrawl.org/overview) qui est un crawler open-source de pages web. Leur site héberge des To et des To de pages HTML crawlées sous format [WARC](https://commoncrawl.org/get-started#Data-Types). \n",
    "\n",
    "But : parser quelques fichiers, par exemple ces crawls sur S3 public: `aws s3 ls --human-readable s3://commoncrawl/crawl-data/CC-MAIN-2024-51/segments/1733066462724.97/warc`, les nettoyer et les indéxer dans Vespa pour y chercher des infos.\n",
    "\n",
    "### Moteur de recherche de bière \n",
    "\n",
    "Possibilité de rester sur les bières du TP et de réaliser un moteur de recherce qui combine \"query textuelle\" qui irait exploiter la DB vectorielle des description, puis enrichirait les résultats avec la DB SQL. Exemple d'enrichissement : proposer un outil d'analyse des brasseries ou des pays qui proposent les bières qui répondent à telle ou telle query textuelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ressources à dispo :\n",
    "- SQL: une nouvelle DB par groupe\n",
    "- Redis: autant de clef que vous le voulez - ne téléscopez pas vos noms de clefs\n",
    "- Spark: tout le cluster est pour vous - synchronisez vous pour partager au mieux les 2 noeuds de 14 coeurs chacun\n",
    "- Vespa: possibilité de créer un index par groupe\n",
    "- Qdrant: possibilité de créer autant de corpus que vous le souhaitez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
